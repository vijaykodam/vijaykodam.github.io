<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Openai on Vijay Kodam</title>
    <link>https://vijay.eu/tags/openai/</link>
    <description>Recent content in Openai on Vijay Kodam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 28 Dec 2025 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://vijay.eu/tags/openai/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>LLM Pricing Comparison</title>
      <link>https://vijay.eu/projects/llm-pricing/</link>
      <pubDate>Sun, 28 Dec 2025 00:00:00 +0000</pubDate>
      
      <guid>https://vijay.eu/projects/llm-pricing/</guid>
      <description>&lt;p&gt;Compare API pricing for text tokens across major Large Language Model providers. All prices are per 1 million tokens in USD.&lt;/p&gt;
&lt;p&gt;Click on any column header to sort the table.&lt;/p&gt;
&lt;div id=&#34;llm-pricing-container&#34;&gt;
    &lt;div id=&#34;llm-pricing-loading&#34;&gt;Loading pricing data...&lt;/div&gt;

    &lt;div id=&#34;llm-pricing-error&#34; style=&#34;display: none;&#34;&gt;
        &lt;p&gt;Failed to load pricing data. Please try again later.&lt;/p&gt;
    &lt;/div&gt;

    &lt;table id=&#34;llm-pricing-table&#34; style=&#34;display: none;&#34;&gt;
        &lt;thead&gt;
            &lt;tr&gt;
                &lt;th data-sort=&#34;provider&#34; class=&#34;sortable&#34;&gt;Provider&lt;/th&gt;
                &lt;th data-sort=&#34;model&#34; class=&#34;sortable&#34;&gt;Model&lt;/th&gt;
                &lt;th data-sort=&#34;input&#34; class=&#34;sortable&#34;&gt;Input / MTok&lt;/th&gt;
                &lt;th data-sort=&#34;cache_input&#34; class=&#34;sortable&#34;&gt;Cache Input / MTok&lt;/th&gt;
                &lt;th data-sort=&#34;output&#34; class=&#34;sortable&#34;&gt;Output / MTok&lt;/th&gt;
            &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody id=&#34;llm-pricing-tbody&#34;&gt;
        &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;div id=&#34;llm-pricing-metadata&#34;&gt;
        &lt;p&gt;&lt;span id=&#34;llm-pricing-last-checked&#34;&gt;&lt;/span&gt;&lt;/p&gt;
        &lt;p&gt;&lt;span id=&#34;llm-pricing-last-updated&#34;&gt;&lt;/span&gt;&lt;/p&gt;
    &lt;/div&gt;

    &lt;div id=&#34;llm-pricing-sources&#34;&gt;
        &lt;p&gt;&lt;strong&gt;Sources:&lt;/strong&gt;&lt;/p&gt;
        &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/docs/pricing#text-tokens&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAI API Pricing&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;https://docs.anthropic.com/en/docs/about-claude/models&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anthropic Claude Pricing&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemini-api/docs/pricing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Gemini API Pricing&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Running Deepseek R1 locally</title>
      <link>https://vijay.eu/posts/running-deepseek-locally/</link>
      <pubDate>Wed, 29 Jan 2025 22:12:06 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/running-deepseek-locally/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/snowdrop.webp&#34; alt=&#34;snowdrop&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here is a video of Deepseek R1 running locally on my Macbook.
Now that everyone is amazed by the low level of resource utilization and open weight model of Deepseek R1, installed 8B model locally.&lt;/p&gt;
&lt;p&gt;With the help of ollama it is as simple as running a single command -
&amp;ldquo;ollama run deepseek-r1:8b&amp;rdquo;
You get your own private, local LLM running securely in your computer.&lt;/p&gt;
&lt;p&gt;My prompt is &amp;ldquo;Generate a five line fairy tale about AI?&amp;rdquo;. In the video, you can see how before generating the response, it thinks. Thinking text is in between &lt;think&gt; and &lt;/think&gt; tags.&lt;/p&gt;
&lt;p&gt;Watch the video to read the five line fairy tale about AI.&lt;/p&gt;
&lt;p&gt;Do you have any experience running Deepseek R1?&lt;/p&gt;
&lt;iframe 
  src=&#34;https://www.youtube.com/embed/CYfpgvsTG9E?si=QKfJcJB1vjJIRWwe&#34; 
  width=&#34;560&#34; 
  height=&#34;315&#34; 
  title=&#34;Embedded Content&#34; 
  frameborder=&#34;0&#34; 
  allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; 
  referrerpolicy=&#34;strict-origin-when-cross-origin&#34;
  allowfullscreen&gt;
&lt;/iframe&gt;

&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
