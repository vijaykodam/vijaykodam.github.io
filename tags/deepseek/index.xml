<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deepseek on Vijay Kodam</title>
    <link>https://vijay.eu/tags/deepseek/</link>
    <description>Recent content in Deepseek on Vijay Kodam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 29 Jan 2025 22:12:06 +0200</lastBuildDate>
    
	<atom:link href="https://vijay.eu/tags/deepseek/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Running Deepseek R1 locally</title>
      <link>https://vijay.eu/ai-lab/running-deepseek-locally/</link>
      <pubDate>Wed, 29 Jan 2025 22:12:06 +0200</pubDate>
      
      <guid>https://vijay.eu/ai-lab/running-deepseek-locally/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/snowdrop.webp&#34; alt=&#34;snowdrop&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here is a video of Deepseek R1 running locally on my Macbook.
Now that everyone is amazed by the low level of resource utilization and open weight model of Deepseek R1, installed 8B model locally.&lt;/p&gt;
&lt;p&gt;With the help of ollama it is as simple as running a single command -
&amp;ldquo;ollama run deepseek-r1:8b&amp;rdquo;
You get your own private, local LLM running securely in your computer.&lt;/p&gt;
&lt;p&gt;My prompt is &amp;ldquo;Generate a five line fairy tale about AI?&amp;rdquo;. In the video, you can see how before generating the response, it thinks. Thinking text is in between &lt;think&gt; and &lt;/think&gt; tags.&lt;/p&gt;
&lt;p&gt;Watch the video to read the five line fairy tale about AI.&lt;/p&gt;
&lt;p&gt;Do you have any experience running Deepseek R1?&lt;/p&gt;
&lt;iframe 
  src=&#34;https://www.youtube.com/embed/CYfpgvsTG9E?si=QKfJcJB1vjJIRWwe&#34; 
  width=&#34;560&#34; 
  height=&#34;315&#34; 
  title=&#34;Embedded Content&#34; 
  frameborder=&#34;0&#34; 
  allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; 
  referrerpolicy=&#34;strict-origin-when-cross-origin&#34;
  allowfullscreen&gt;
&lt;/iframe&gt;

&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New metric to measure the efficiency of AI models</title>
      <link>https://vijay.eu/posts/new-llm-metric/</link>
      <pubDate>Tue, 28 Jan 2025 20:03:20 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/new-llm-metric/</guid>
      <description>&lt;p&gt;At the end of the day, how cheaply and energy efficiently can you generate tokens matters.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;strong&gt;Tokens per watt per dollar&lt;/strong&gt;&amp;rdquo; metric mentioned by Satya Nadella, CEO of Microsoft, is trying to achieve the same.&lt;/p&gt;
&lt;p&gt;This will be a metric by which every LLM is going to be benchmarked against. This is the metric which will showcase how long can an AI investment lasts and how much is your profitability of AI startups.&lt;/p&gt;
&lt;p&gt;There will be a comparison of LLMs with &amp;ldquo;Tokens per watt per dollar&amp;rdquo; soon, if not already existing.&lt;/p&gt;
&lt;p&gt;I would love to hear your thoughts on this?&lt;/p&gt;
&lt;p&gt;This is &lt;a href=&#34;https://www.linkedin.com/posts/satyanadella_wef25-activity-7287900710770196480-7mn6/&#34;&gt;related post&lt;/a&gt; by Satya.&lt;/p&gt;
&lt;p&gt;If you have not already watched, highly recommend Satya Nadella&amp;rsquo;s &lt;a href=&#34;https://www.youtube.com/watch?v=kOkDTvsUuWA&amp;amp;t=156s&#34;&gt;AI Tour Keynote: London&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
