<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cloud on Vijay Kodam&#39;s Website</title>
    <link>https://vijay.eu/categories/cloud/</link>
    <description>Recent content in Cloud on Vijay Kodam&#39;s Website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 30 Dec 2024 01:04:17 +0200</lastBuildDate>
    
	<atom:link href="https://vijay.eu/categories/cloud/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>What is ARC Zonal shift feature in EKS?</title>
      <link>https://vijay.eu/posts/eks-arc-zonal-shift/</link>
      <pubDate>Mon, 30 Dec 2024 01:04:17 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/eks-arc-zonal-shift/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/snowdrop.png&#34; alt=&#34;snowdrop&#34;&gt;
&lt;em&gt;Image Credits:&lt;/em&gt; Generated using DALL.E. &lt;em&gt;This image depicts &lt;strong&gt;resiliency&lt;/strong&gt; in nature similar to what is expected from your AWS architecture :)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Recently I have created an EKS Auto mode cluster and observed that &lt;strong&gt;‚ÄúARC Zonal shift‚Äù&lt;/strong&gt; feature was enabled for my EKS cluster.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Amazon Application Recovery Controller (ARC)&lt;/strong&gt; helps simplify and automate recovery for highly available applications. It was initially known as ‚ÄúRoute 53 ARC‚Äù and since then has expanded to support Amazon EC2 Auto scaling groups, ALB, NLB and now EKS. So it is now just Amazon ARC.&lt;/p&gt;
&lt;p&gt;You can recover from an impaired Availability Zone (AZ) using ARC Zonal Shift and Zonal autoshift. Zonal shift is used when you manually trigger it to shift traffic away from an impaired AZ. Use Zonal autoshift to let AWS monitor and shift traffic on your behalf.&lt;/p&gt;
&lt;p&gt;If you want to run resilient and highly available applications across multi-AZs in EKS and you want to survive an AZ going down then this is the feature (EKS Zonal Shift) you need.&lt;/p&gt;
&lt;p&gt;Remember that this will only redirect internal east-west traffic inside your EKS traffic between your pods. If you want to redirect traffic from loadbalancers similarly then you have to enable an ALB or NLB with ARC Zonal shift.&lt;/p&gt;
&lt;p&gt;Performing a zonal shift enables you to achieve rapid recovery from application failures in a single Availability Zone (AZ). This is helpful to build resilience in case of an AZ impairment or when an AZ is down.&lt;/p&gt;
&lt;p&gt;You can enable it from EKS cluster creation step or enable it afterwards for already running clusters. If you are creating EKS auto mode cluster with ‚ÄúQuick configuration‚Äù option then ARC Zonal shift is enabled by default.&lt;/p&gt;
&lt;p&gt;With zonal shift, you can temporarily mitigate issues and incidents by triggering a shift and redirecting in-cluster network traffic to a healthy AZ.&lt;/p&gt;
&lt;p&gt;For this to work, you should already be running EKS worker nodes in multiple AZs (at least three) for HA and resiliency and your applications are already running in multiple AZs. So if your application is already running in three different AZs and if one AZ is impaired then Zonal shift will redirect traffic away from impaired AZ to healthy AZs. In this case, you will have your application running in two AZs as highly available after the third one went down.&lt;/p&gt;
&lt;p&gt;Ideally such setup comes with cost so use it for highly critical workloads where you need such level of high-availability and resiliency.&lt;/p&gt;
&lt;p&gt;Check the EKS Zonal shift documentation to learn more: &lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/zone-shift.html&#34;&gt;https://docs.aws.amazon.com/eks/latest/userguide/zone-shift.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Follow me on LinkedIn for more content related to Kubernetes, EKS and AWS in general. Visit my website at &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;https://vijay.eu/posts&lt;/a&gt; for all my posts in one place.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Do you know that EKS Auto Mode enforces a 21-day maximum node lifetime?</title>
      <link>https://vijay.eu/posts/eks-auto-max-node-lifetime/</link>
      <pubDate>Thu, 12 Dec 2024 14:13:02 +0530</pubDate>
      
      <guid>https://vijay.eu/posts/eks-auto-max-node-lifetime/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/EKS-Auto-Mode.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;Do you know that EKS Auto Mode enforces a 21-day maximum node lifetime?&lt;/p&gt;
&lt;p&gt;EKS Auto mode cluster manages worker nodes on your behalf.
Karpenter deletes worker nodes in EKS auto mode nodepools after 21 days of node lifetime. This is the maximum node lifetime. It will be replaced with a new node.&lt;/p&gt;
&lt;p&gt;This is needed for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;providing security patches&lt;/li&gt;
&lt;li&gt;OS updates&lt;/li&gt;
&lt;li&gt;component upgrades&lt;/li&gt;
&lt;li&gt;improves security posture&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-if-you-want-to-modify-the-maximum-node-lifetime&#34;&gt;What if you want to modify the maximum node lifetime?&lt;/h2&gt;
&lt;p&gt;You can reduce the maximum node lifetime by creating a custom NodePool with ‚Äúspec.template.spec.expireAfter‚Äù with a value of node lifetime in hours. Max is 21 days.&lt;/p&gt;
&lt;h2 id=&#34;how-to-disable-it&#34;&gt;How to disable it?&lt;/h2&gt;
&lt;p&gt;If for some reason, you do not want to delete worker nodes so frequent or if you want to keep the nodes static then you can create a new Managed Node Group and add nodes in it.
You can create both EKS Auto mode nodepools and Managed Node groups (without auto mode) in the same EKS cluster. These are called mixed-mode clusters.
I will be covering more about mixed-mode clusters in future posts.&lt;/p&gt;
&lt;p&gt;For more insights on EKS, AWS, Kubernetes, and Cloud Architecture, follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and check out &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt; for all my blog posts in one place.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>First Impressions of EKS Auto Mode ‚Äì A Game Changer!</title>
      <link>https://vijay.eu/posts/eks-auto-first-impressions/</link>
      <pubDate>Wed, 04 Dec 2024 23:13:15 +0530</pubDate>
      
      <guid>https://vijay.eu/posts/eks-auto-first-impressions/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/aws-eks-pic.png&#34; alt=&#34;Kubernetes&#34;&gt;
&lt;em&gt;Image Credit: From AWS EKS Blog&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Here are my thoughts after initial few days of using &lt;strong&gt;EKS Auto mode&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;AWS has truly raised the bar with EKS Auto Mode, a new feature announced at &lt;strong&gt;re:Invent 2024&lt;/strong&gt;. This innovation automates much of the undifferentiated heavy lifting, allowing customers to focus on what matters most: building great applications.&lt;/p&gt;
&lt;h2 id=&#34;my-hands-on-experience&#34;&gt;My Hands-On Experience&lt;/h2&gt;
&lt;p&gt;I set up an EKS Auto Mode cluster from scratch and was pleasantly surprised by how much AWS now handles post-installation. You can read in &lt;a href=&#34;https://www.linkedin.com/pulse/how-create-eks-auto-mode-cluster-vijay-kumar-kodam-oqw4f/&#34;&gt;more detail about it here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let me break down what &lt;em&gt;Day 2 operations&lt;/em&gt; typically involve:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Managed Node Groups&lt;/strong&gt;: Create managed node groups and wait for worker nodes to come up.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;EKS Node capabilities&lt;/strong&gt;: Most of them were running as Kubernetes Daemonsets on worker nodes before. Now they run as system processes managed by AWS. This includes components such as service discovery, service load balancing, pod networking, block storage, and credential vending.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add-Ons Installation&lt;/strong&gt;: Select and install versions for multiple EKS add-ons (latest, standard, or older). Like coredns, EBS CSI driver, CNI driver, EKS pod identity etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Load Balancer Controller&lt;/strong&gt;: Install the AWS Load Balancer Controller for ingress traffic handling.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cost Optimization&lt;/strong&gt;: Install Karpenter to manage pod bin-packing, scale nodes dynamically, and select cost-efficient EC2 instances.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OS Security patching&lt;/strong&gt;: Address OS security vulnerabilities identified by AWS Security Hub.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cluster Upgrades&lt;/strong&gt;: Over time, you need to upgrade Kubernetes control plane versions and meticulously plan worker node updates. This is a continuous process every 3-6 months.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, imagine all these tasks being automated by AWS. That‚Äôs EKS Auto Mode for you!&lt;/p&gt;
&lt;h2 id=&#34;key-highlights-from-my-testing&#34;&gt;Key Highlights from My Testing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;No Idle Nodes&lt;/strong&gt;: When I launched my first EKS Auto Mode cluster, there were no worker nodes running initially‚Äîjust built-in &amp;ldquo;general-purpose&amp;rdquo; and &amp;ldquo;system&amp;rdquo; node pools.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dynamic Scaling&lt;/strong&gt;: After deploying my first application, Karpenter automatically spun up a worker node tailored to the app&amp;rsquo;s resource requirements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cost Efficiency&lt;/strong&gt;: Upon deleting the application, Karpenter scaled down the node, saving money by avoiding idle resources.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This level of automation simplifies cluster operations and significantly reduces costs.&lt;/p&gt;
&lt;h2 id=&#34;pricing-update&#34;&gt;Pricing Update&lt;/h2&gt;
&lt;p&gt;EKS Auto Mode introduces a pay-as-you-go control plane pricing model based on the number of EC2 worker nodes, a shift from the flat fee for the standard EKS control plane. While it‚Äôs a slight increase in cost, the time and effort saved make it a Win-Win for both AWS and customers. Find more about &lt;a href=&#34;https://aws.amazon.com/eks/pricing/&#34;&gt;EKS Auto mode pricing here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What‚Äôs Next?&lt;/h2&gt;
&lt;p&gt;I‚Äôve &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7269311743338663936/&#34;&gt;created a demo video&lt;/a&gt; showcasing EKS Auto Mode in action. If you‚Äôre curious, I highly recommend giving this feature a try!&lt;/p&gt;
&lt;p&gt;For more insights on EKS, AWS, Kubernetes, and Cloud Architecture, follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; or check out my blog at &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;https://vijay.eu/posts&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let me know your thoughts on this exciting new feature! üëá&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to secure microservices architecture in AWS?</title>
      <link>https://vijay.eu/posts/aws-secure-microservices/</link>
      <pubDate>Mon, 04 Nov 2024 00:06:59 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/aws-secure-microservices/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/ms-secure.png&#34; alt=&#34;aws-security&#34;&gt;
&lt;strong&gt;Image Credits:&lt;/strong&gt; Microservices architecture image made by me using draw.io&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Security in Public Cloud is utmost important. Losing access to your website or attackers deleting your database are catastrophic-company-ending-events.&lt;/p&gt;
&lt;h3 id=&#34;shared-responsibility-model&#34;&gt;Shared Responsibility Model&lt;/h3&gt;
&lt;p&gt;Security and Compliance is a shared responsibility between AWS and the customer.&lt;/p&gt;
&lt;p&gt;Here is the definition from AWS documentation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;AWS is responsible for the &lt;strong&gt;&amp;ldquo;Security of the Cloud&amp;rdquo;&lt;/strong&gt;. AWS is responsible for protecting the infrastructure that runs all of the services offered in the AWS Cloud. This infrastructure is composed of the hardware, software, networking, and facilities that run AWS Cloud services.&lt;/p&gt;
&lt;p&gt;Customer is responsible for the &lt;strong&gt;‚ÄúSecurity in the Cloud‚Äù&lt;/strong&gt;. Customer responsibility will be determined by the AWS Cloud services that a customer selects. This determines the amount of configuration work the customer must perform as part of their security responsibilities.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Refer AWS Documentation for more information on Shared Responsibility Model.&lt;/p&gt;
&lt;h3 id=&#34;best-practices&#34;&gt;Best Practices&lt;/h3&gt;
&lt;p&gt;Luckily, AWS provides you with a host of security services to improve your security posture from Day One. Note that this is not an exhaustive list and &amp;ldquo;it depends&amp;rdquo; on where you run and what services you use. Here are some of the steps to secure your microservices architecture in AWS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use AWS Shield for DDoS protection&lt;/li&gt;
&lt;li&gt;Use AWS GuardDuty for intelligent threat detection.&lt;/li&gt;
&lt;li&gt;Use AWS IAM for managing identities and access to AWS resources&lt;/li&gt;
&lt;li&gt;Use AWS WAF to protect your web applications from common exploits.&lt;/li&gt;
&lt;li&gt;Use AWS Certificates Manager for encrypting website data in transit using TLS/SSL certificates.&lt;/li&gt;
&lt;li&gt;Use AWS KMS keys to encrypt all EBS volumes and Aurora DB (data at rest)&lt;/li&gt;
&lt;li&gt;Use AWS Secrets Manager to store your application secrets.&lt;/li&gt;
&lt;li&gt;Run all your workloads in private subnets. Allow only needed traffic using Security Groups and NACLs.&lt;/li&gt;
&lt;li&gt;If your applications need Internet connectivity to download updates then configure NAT GW in public subnet.&lt;/li&gt;
&lt;li&gt;You could also use VPC peering to isolate specific workloads in a different VPC in a different AWS account.&lt;/li&gt;
&lt;li&gt;Use Amazon Inspector to scan EC2 for security vulnerabilities&lt;/li&gt;
&lt;li&gt;Use Amazon Security Hub to automate AWS security checks and centralize security alerts.&lt;/li&gt;
&lt;li&gt;Use AWS Cognito for authentication and authorization of the API requests.&lt;/li&gt;
&lt;li&gt;Use CloudTrail for audit logging.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Security should not be an after thought when building and running applications in AWS. Utilize some or all of these AWS security services to make your microservices architecture secure.&lt;/p&gt;
&lt;p&gt;What have I missed? This post assumed microservices are running in EC2 VMs. If microservices are running in Amazon EKS then it calls for a totally new approach and very long post. I will post about EKS security soon.&lt;/p&gt;
&lt;p&gt;Follow me on LinkedIn at &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;https://www.linkedin.com/in/vijaykodam/&lt;/a&gt; where I post articles about AWS, Kubernetes and cloud computing in general. I also post all my articles to my blog at &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;https://vijay.eu/posts&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Save Hours During Amazon EKS Upgrades with This One Simple Step!</title>
      <link>https://vijay.eu/posts/eks-upgrade-insights/</link>
      <pubDate>Thu, 03 Oct 2024 01:00:19 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/eks-upgrade-insights/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/K8s.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;üöÄ Save Hours During Amazon EKS Upgrades with This One Simple Step! üöÄ&lt;/p&gt;
&lt;p&gt;If you‚Äôve ever managed EKS clusters in production, you know how crucial it is to keep them updated to leverage the latest features and maintain security.&lt;/p&gt;
&lt;p&gt;üîÑ But before starting an upgrade, have you checked the &amp;ldquo;Upgrade Insights&amp;rdquo; tab on the EKS cluster page?&lt;/p&gt;
&lt;p&gt;Previously, our team had to manually check for deprecations and potential issues before every upgrade, spending hours in the process. Now, with the &amp;ldquo;Upgrade Insights&amp;rdquo; feature, EKS continuously monitors audit logs, detects deprecation errors, and updates the insights daily.&lt;/p&gt;
&lt;p&gt;This small step has transformed our process and saved us countless hours of debugging and maintenance. üí°&lt;/p&gt;
&lt;p&gt;‚úÖ &lt;strong&gt;Pro tip&lt;/strong&gt;: Always review the &amp;ldquo;Upgrade Insights&amp;rdquo; tab before upgrading your clusters to ensure a smooth transition to newer Kubernetes versions.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback by commenting on my LinkedIn post below.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/posts/activity-7247354293660356609-IT7t&#34;&gt;https://www.linkedin.com/posts/activity-7247354293660356609-IT7t&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Where Should I Deploy My K8s Cluster?</title>
      <link>https://vijay.eu/posts/deploy-k8s/</link>
      <pubDate>Sun, 17 May 2020 01:00:19 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/deploy-k8s/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/K8s.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;This week there was an &lt;a href=&#34;https://www.redhat.com/en/blog/red-hat-and-aws-extend-collaboration-introducing-amazon-red-hat-openshift&#34;&gt;announcement&lt;/a&gt; about Amazon Red Hat Openshift. It is an enterprise Kubernetes (K8s) service on AWS jointly managed and supported by AWS and Red Hat. Upon reading more about the service, found out that Red Hat already has two more OpenShift services available on AWS. If you count AWS&amp;rsquo; own managed K8s service Amazon Elastic Kubernetes Service (EKS) then there are four different ways you can run a K8s cluster on top of AWS. I am sure there are many other companies providing similar managed K8s services on top of AWS.&lt;/p&gt;
&lt;p&gt;For a beginner starting to use K8s this is overwhelming. This brings us to the question: &lt;strong&gt;Where should I deploy my K8s cluster?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As always, the answer is: &lt;strong&gt;It Depends&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It depends&lt;/strong&gt; on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your team&amp;rsquo;s K8s expertise&lt;/li&gt;
&lt;li&gt;Your company&amp;rsquo;s budget&lt;/li&gt;
&lt;li&gt;Your data locality requirements&lt;/li&gt;
&lt;li&gt;Your preferred Cloud Vendor&lt;/li&gt;
&lt;li&gt;Your company&amp;rsquo;s already existing deals with Software vendors&lt;/li&gt;
&lt;li&gt;and many more.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You could run your K8s cluster in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On Premises&lt;/li&gt;
&lt;li&gt;Hybrid Cloud&lt;/li&gt;
&lt;li&gt;IaaS&lt;/li&gt;
&lt;li&gt;PaaS&lt;/li&gt;
&lt;li&gt;Others&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;on-premises&#34;&gt;On Premises&lt;/h3&gt;
&lt;p&gt;If you already own datacenters or if you have strict privacy/security requirements for making sure the data does not leave your premises then &lt;em&gt;On Premises&lt;/em&gt; solution is the way to go.&lt;/p&gt;
&lt;p&gt;Install host operating system on the bare metal servers and then install K8s on top of it. Kubeadm is one option. However, be aware that this is a bare bones solution. You have to build/integrate authentication, authorization, dashboard, security, networking plugins, service mesh, storage, the list goes on.&lt;/p&gt;
&lt;p&gt;You could choose to install Openshift or Rancher. These come fully loaded.&lt;/p&gt;
&lt;p&gt;On Premises solutions are usually the slowest ones  to complete the installation as you have to deal  with hardware. It takes time to order, ship, install and configure them.&lt;/p&gt;
&lt;h3 id=&#34;hybrid-cloud&#34;&gt;Hybrid Cloud&lt;/h3&gt;
&lt;p&gt;Amazon Outposts, Google Anthos and Azure Stack provide rack full of servers which you can install in your datacenter. These racks are connected to their Public cloud and you manage it just like VMs on public cloud.&lt;/p&gt;
&lt;p&gt;This option gives you the flexibility of cloud deployment with the advantage of not managing the hardware.&lt;/p&gt;
&lt;p&gt;Keep in mind that this is the most costliest option. Bill can run into millions easily.&lt;/p&gt;
&lt;p&gt;Once you have Outposts, Anthos or Azure Stack rack on premises, you can use their managed K8s solution on top of it. Google Anthos GKE is one such option.&lt;/p&gt;
&lt;p&gt;The timeline depends on the cloud provider and honestly I have no idea about it.&lt;/p&gt;
&lt;h3 id=&#34;iaas&#34;&gt;IaaS&lt;/h3&gt;
&lt;p&gt;If you need full control of the K8s cluster and you are a pro in managing K8s then this is the option to go.&lt;/p&gt;
&lt;p&gt;You install K8s on top of Amazon EC2 or Google Compute Engine or Azure Virtual Machine.&lt;/p&gt;
&lt;p&gt;Several K8s deployment tools like kops, kubespray or KRIB exist. You can also install Red Hat Openshift or Rancher on the virtual machines.&lt;/p&gt;
&lt;p&gt;Use this option only when you have experience running k8s clusters.&lt;/p&gt;
&lt;h3 id=&#34;paas&#34;&gt;PaaS&lt;/h3&gt;
&lt;p&gt;If all you wanted is a K8s cluster and don&amp;rsquo;t know or don&amp;rsquo;t want to know K8s cluster management then this option is for you.&lt;/p&gt;
&lt;p&gt;Managed K8s solutions like Google GKE, Amazon EKS, Amazon Red Hat Openshift, Azure AKS does fit the bill.&lt;/p&gt;
&lt;p&gt;You click a button and you get a cluster and the kubeconfig/credentials to the cluster.&lt;/p&gt;
&lt;p&gt;You might want to customize some options, enable logging, move the API server to private endpoint etc.&lt;/p&gt;
&lt;p&gt;Usually this is a good place to start for development clusters. Deploy the k8s cluster, tune it, test it, run your applications and then customize more.&lt;/p&gt;
&lt;p&gt;Since this is a managed solution, you will not have full control of the cluster. You have to use whatever version they support, don&amp;rsquo;t get access to the API server or etcd servers barring some flags.&lt;/p&gt;
&lt;h3 id=&#34;others&#34;&gt;Others&lt;/h3&gt;
&lt;p&gt;Minikube, kind, k3s are for developments purposes. These software are light weight and are designed to run on your laptop.&lt;/p&gt;
&lt;p&gt;These solutions can be used for learning about k8s, for local testing of your applications.&lt;/p&gt;
&lt;p&gt;K8s distributions like Red Hat Openshift or Rancher can be installed on bare metal, IaaS, and  PaaS. Usually this option is useful if you have more than one type of infrastructure and you want to use the same K8s distribution everywhere. You could build automation on top of it and deploy it any where you want.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this blog post I have tried to cover different ways you can deploy your kubernetes cluster. This list is not exhaustive and I might have missed some options.&lt;/p&gt;
&lt;p&gt;Kubernetes has become the industry standard for running containers and all the major public cloud providers have K8s services.&lt;/p&gt;
&lt;p&gt;Purpose of writing this blog post is to showcase the variety of K8s deployment options you have, be it on a bare metal server, or virtual machine or managed solution like this week&amp;rsquo;s announcement of Amazon Red Hat Openshift.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback by commenting on my tweet below.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Where should I deploy my K8s cluster?&lt;br&gt;My new blog post on this topic.&lt;a href=&#34;https://t.co/sflPzY3Rnt&#34;&gt;https://t.co/sflPzY3Rnt&lt;/a&gt;&lt;br&gt;&lt;br&gt;Do read it and give me feedback.&lt;/p&gt;&amp;mdash; Vijay Kodam (@vijaykodam) &lt;a href=&#34;https://twitter.com/vijaykodam/status/1261783876596350976?ref_src=twsrc%5Etfw&#34;&gt;May 16, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


</description>
    </item>
    
    <item>
      <title>How to login securely to your Amazon EC2 Instance?</title>
      <link>https://vijay.eu/posts/how-to-login-securely-to-amazon-ec2/</link>
      <pubDate>Tue, 12 May 2020 14:42:15 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/how-to-login-securely-to-amazon-ec2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/secure-ec2.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Securing the Amazon EC2 instance is the first thing you have to think while creating it. This post specifically talks about how to secure SSH/RDP port on your EC2 Instances and how not to open port 22/3389 to the Internet (0.0.0.0/0).&lt;/p&gt;
&lt;p&gt;There are several ways to secure your EC2 instances in AWS. Will discuss some of the popular ones.&lt;/p&gt;
&lt;p&gt;When EC2 instance is running in Public subnet, disable password authentication and enable SSH keys based authentication. Secure your SSH port to allow traffic from specific subnet (Ex., 3.2.132.0/24) or your own IP address (Eg., 3.2.132.23/32) by setting security group rules.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;a href=&#34;https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html&#34;&gt;*security group&lt;/a&gt;* acts as a virtual firewall for your instance to control inbound and outbound traffic.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Problem with this method is that whenever your IP address or subnet changes you have to update your security group rules. Managing SSH keys is another task, which can get quite tricky when there are more than few EC2 instances. How to store the SSH keys safely? How to grant or revoke accesses to specific users?&lt;/p&gt;
&lt;p&gt;Another way is to use bastion host, run it in Public subnet and expose it to Internet using security group rules. Create your EC2 instances in a private subnet where there is no access from Internet and no one from outside can access it. Use security group rules to allow SSH traffic into your instance only from the bastion. This way your EC2 instance traffic is secured and only from bastion host you can access your EC2 instance.&lt;/p&gt;
&lt;p&gt;However, the same problem exists as before. How will you secure your SSH/RDP port on the bastion host. You will still have to manage the SSH keys to your bastion host and open inbound ports on the instance.&lt;/p&gt;
&lt;h2 id=&#34;aws-systems-manager-session-manager&#34;&gt;AWS Systems Manager Session Manager&lt;/h2&gt;
&lt;p&gt;Session Manager is part of AWS Systems Manager service. It gives you a browser-based CLI window to access your Windows and Linux EC2 instances without opening inbound SSH/RDP port. No need to create a bastion host. No need to manage SSH keys. Access can be granted or revoked using AWS IAM.&lt;/p&gt;
&lt;p&gt;AWS Systems Manager uses SSM agent running on the EC2 instance to manage the login and other tasks.&lt;/p&gt;
&lt;p&gt;SSM Agent is preinstalled, by default, on the following Amazon Machine Images (AMIs):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Windows Server 2008-2012 R2 AMIs published in November 2016 or later&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Windows Server 2016 and 2019&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Amazon Linux&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Amazon Linux 2&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ubuntu Server 16.04&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ubuntu Server 18.04&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Amazon ECS-Optimized&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You need to create relevant IAM permissions, install or enable SSM agent on the EC2 instances. Once you do it you can either acces your instance from AWS Console or AWS CLI.&lt;/p&gt;
&lt;p&gt;For detailed instructions, refer to &lt;a href=&#34;https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-getting-started.html&#34;&gt;the documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;AWS Systems Manager Sessions Manager lets you manage your entire fleet of EC2 instances, audit the access, grant or revoke access for each instance.&lt;/p&gt;
&lt;h3 id=&#34;notes&#34;&gt;Notes&lt;/h3&gt;
&lt;p&gt;Beware of pressing CTRL-W if you are used to it on the bash shell. It will close your browser window. Change the keyboard shortcuts to update the shortcut.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback or comments on my tweet below:
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;How to login securely to Amazon EC2 without opening SSH port to 0.0.0.0/0.&lt;a href=&#34;https://t.co/iAPvnoawwN&#34;&gt;https://t.co/iAPvnoawwN&lt;/a&gt;&lt;br&gt;&lt;br&gt;This tweet is used for allowing readers to comment on my blogpost. &lt;br&gt;Since it is hosted as static pages using Hugo thought this is a good way to include commenting on my blogpost.&lt;/p&gt;&amp;mdash; Vijay Kodam (@vijaykodam) &lt;a href=&#34;https://twitter.com/vijaykodam/status/1260837110812155904?ref_src=twsrc%5Etfw&#34;&gt;May 14, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ambassador API GW and Keycloak integration</title>
      <link>https://vijay.eu/posts/ambassador-keycloak-integration/</link>
      <pubDate>Sun, 23 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vijay.eu/posts/ambassador-keycloak-integration/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/cloud.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.getambassador.io/&#34;&gt;Ambassador API GW&lt;/a&gt; is an open source, Kubernetes-Native microservices API Gateway built on the Envoy Proxy.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.keycloak.org/&#34;&gt;Keycloak&lt;/a&gt; is an open source identity and access management solution. Keycloak supports OpenID Connect, SAML, OAuth2 and LDAP.&lt;/p&gt;
&lt;p&gt;Ambassador supports authenticating incoming requests. When configured, Ambassador will check with a third party authentication service prior to routing an incoming request. An AuthService manifest configures Ambassador to use an external service to check authentication and authorization for incoming requests. Each incoming request is authenticated before routing to its destination.&lt;/p&gt;
&lt;p&gt;In this blog we will be using Keycloak as our IAM solution and integrating it with Ambassador API GW. After integrating Keycloak with Ambassador, incoming API requests will be redirected to Keycloak login page for authentication before allowing access to those APIs.&lt;/p&gt;
&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Ambassador API GW is deployed and listening for API requests. Follow the &lt;a href=&#34;https://www.getambassador.io/user-guide/getting-started&#34;&gt;official instructions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;httpbin example application is configured for the URL: &lt;code&gt;http://&amp;lt;Ambassador URL&amp;gt;/httpbin&lt;/code&gt;
You can follow the instructions mentioned &lt;a href=&#34;https://www.getambassador.io/user-guide/getting-started/#3-creating-your-first-route&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Make sure &lt;code&gt;http://&amp;lt;Ambassador URL&amp;gt;/httpbin&lt;/code&gt; is routed through Ambassador API GW and it should open &lt;code&gt;httpbin.org&lt;/code&gt; website.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In some of the commands below, you need to substitute relevant IP or URL for Keycloak and Ambassador. You will find them in this notation: &lt;code&gt;&amp;lt;Ambassador IP-or-URL&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;Your-Keycloak-IP-or-URL&amp;gt;&lt;/code&gt;.       Similarly there are other variables in &lt;code&gt;&amp;lt; &amp;gt;&lt;/code&gt; which you need to substitute before running those commands.&lt;/p&gt;
&lt;h2 id=&#34;set-up-keycloak&#34;&gt;Set up Keycloak&lt;/h2&gt;
&lt;p&gt;Use your existing keycloak setup if you already have. If not you can start one quicky using below instructions.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Please note that below keycloak setup is not secure and is used only for testing the Ambassador-Keycloak integration. Do not use this in production. Use it at your own risk.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For testing purposes docker version of keycloak will be used for this demo.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;docker run -e KEYCLOAK_USER=&amp;lt;add-your-keycloak-user&amp;gt; \
            -e KEYCLOAK_PASSWORD=&amp;lt;keycloak-password&amp;gt; \
                                  -p 0.0.0.0:80:8080 \
                                -itd --name keycloak \
                                      jboss/keycloak
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Above command will start keycloak on your Linux machine. It will set admin username, password and binds keycloak to port 80. This setup uses keycloak&amp;rsquo;s default H2 DB, which should not be used in production. Note your IP address.&lt;/p&gt;
&lt;p&gt;Login to Keycloak by visiting &lt;code&gt;http://&amp;lt;your-ip&amp;gt;&lt;/code&gt; in your browser. Use the username and password supplied in the docker run command to login to Keycloak.&lt;/p&gt;
&lt;p&gt;Use the existing &amp;ldquo;master&amp;rdquo; realm. Create a client and a user for our testing purposes.
Click on &lt;code&gt;Clients -&amp;gt; Create&lt;/code&gt;. Create button is on the right side of the page.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture6.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Add &lt;code&gt;Client ID&lt;/code&gt; as &lt;code&gt;test&lt;/code&gt;. Select &amp;ldquo;&lt;code&gt;Client Protocol&lt;/code&gt;&amp;rdquo; as &amp;ldquo;openid-connect&amp;rdquo;. You can leave other fields empty. Click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture1.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;After saving, a new window will open with more details. Turn On &lt;code&gt;Authorization Enabled&lt;/code&gt; option. It will automatically turn On &lt;code&gt;Service Accounts Enabled&lt;/code&gt; option. Leave it like that.&lt;/p&gt;
&lt;p&gt;Fill &lt;code&gt;Valid Redirect URIs&lt;/code&gt; with &lt;code&gt;http://&amp;lt;Ambassador URL&amp;gt;/*&lt;/code&gt;. Click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture2.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture8.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;On the same page, go to &lt;code&gt;Credentials&lt;/code&gt; tab as shown below. Note the secret which is needed when creating &amp;ldquo;ambassador-auth-client-secret&amp;rdquo; in the next section. Use it wherever &lt;code&gt;&amp;lt;YOUR_OIDC_CLIENT_SECRET&amp;gt;&lt;/code&gt; is mentioned.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture4.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Click Users section on the keycloak page, to create users. Add username, email and select email verified. Click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture9.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the same page, go to Credentials tab.  Set the new password, and turn Temporary to Off.&lt;br&gt;
Click Reset Password.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture10.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;When dialog window opens click Change Password.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture11.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Please note that this is done only for testing ambassador-keycloak integration. 
Please do not do this in production or in any setup. Follow these instructions at your own risk.&lt;/p&gt;
&lt;p&gt;Now go back and click Users section in Keycloak. In the Users page, click &amp;ldquo;View all Users&amp;rdquo; and you should see the newly created user.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture12.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;setup-oidc-auth-integration-with-keycloak&#34;&gt;Setup OIDC Auth integration with Keycloak&lt;/h2&gt;
&lt;p&gt;Thanks to Antti Myyra for developing Ambassador-Auth-OIDC, which will be used to integrate Keycloak with Ambassador API GW.&lt;/p&gt;
&lt;p&gt;Run below commands to clone ambassador-auth-oidc. Below you can choose to run it either in docker or in k8s. Don&amp;rsquo;t run both.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;git clone https://github.com/ajmyyra/ambassador-auth-oidc.git
cd ambassador-auth-oidc/
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;running-ambassador-auth-in-docker&#34;&gt;Running ambassador auth In Docker&lt;/h3&gt;
&lt;p&gt;Use these instructions if your Ambassador API gateway is running as docker container and not in k8s.&lt;/p&gt;
&lt;p&gt;Above setup is running keycloak as docker container and listening on port 80. Below ambassador-auth-oidc docker container will listen on port 8080.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;docker run -p 0.0.0.0:8080:8080 \
      -e OIDC_PROVIDER=&amp;#34;http://&amp;lt;Your-Keycloak-IP-or-URL&amp;gt;/auth/realms/master&amp;#34; \
      -e SELF_URL=&amp;#34;http://&amp;lt;Ambassador IP-or-URL&amp;gt;:8080&amp;#34; \
      -e OIDC_SCOPES=&amp;#34;profile email&amp;#34; \
      -e CLIENT_ID=&amp;#34;test&amp;#34; \
      -e CLIENT_SECRET=&amp;#34;&amp;lt;YOUR_OIDC_CLIENT_SECRET&amp;gt;&amp;#34; \
      ajmyyra/ambassador-auth-oidc:1.3
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;running-ambassador-auth-in-kubernetes&#34;&gt;Running Ambassador Auth in Kubernetes&lt;/h3&gt;
&lt;p&gt;Use this setup if you are already running Ambassador API GW in K8s.
Make sure Ambassador API GW is up and running before creating secrets.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl create secret generic ambassador-auth-jwt-key --from-literal=jwt-key=$(openssl rand -base64 64|tr -d &amp;#39;\n &amp;#39;)
kubectl create secret generic ambassador-auth-redis-password --from-literal=redis-password=$(openssl rand -base64 20)
kubectl create secret generic ambassador-auth-oidc-provider --from-literal=oidc-provider=&amp;#34;http://&amp;lt;Your-Keycloak-IP-or-URL&amp;gt;/auth/realms/master&amp;#34;
kubectl create secret generic ambassador-auth-self-url --from-literal=self-url=&amp;#34;http://&amp;lt;Ambassador IP-or-URL&amp;gt;&amp;#34;
kubectl create secret generic ambassador-auth-client-id --from-literal=client-id=&amp;#34;test&amp;#34;
kubectl create secret generic ambassador-auth-client-secret --from-literal=client-secret=&amp;lt;YOUR_OIDC_CLIENT_SECRET&amp;gt;
kubectl get secrets # To confirm they&amp;#39;ve been created
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Run below commands in the root directory of ambassador-auth-oidc. This will start the ambassador-auth-oidc container on K8s.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;cd ambassador-auth-oidc/
cp misc/auth-deployment.yaml.example auth-deployment.yaml
cp misc/auth-service.yaml.example auth-service.yaml

kubectl create -f auth-deployment.yaml
kubectl create -f auth-service.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Make sure ambassador-auth-oidc is up and running. Also check the logs to make sure everything is alright.&lt;/p&gt;
&lt;p&gt;Now go to &lt;code&gt;http://&amp;lt;Ambassador IP-or-URL&amp;gt;/httpbin&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It should automatically redirect you to Keycloak page for logging in.
Enter your &amp;ldquo;test&amp;rdquo; user credentials. After successful login it should automatically redirect you to &lt;code&gt;http://&amp;lt;Ambassador IP-or-URL&amp;gt;/httpbin&lt;/code&gt; page.&lt;/p&gt;
&lt;p&gt;We have successfully integrated Keycloak with Ambassador API GW and tested API Authentication.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
