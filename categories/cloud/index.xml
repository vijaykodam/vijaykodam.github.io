<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cloud on Vijay Kodam</title>
    <link>https://vijay.eu/categories/cloud/</link>
    <description>Recent content in Cloud on Vijay Kodam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 04 Mar 2025 01:53:52 +0200</lastBuildDate>
    
	<atom:link href="https://vijay.eu/categories/cloud/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>MLOps 101</title>
      <link>https://vijay.eu/posts/mlops-101/</link>
      <pubDate>Tue, 04 Mar 2025 01:53:52 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/mlops-101/</guid>
      <description>&lt;h3 id=&#34;what-is-mlops&#34;&gt;What is MLOps?&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;MLOps&lt;/strong&gt; is set of practices that streamline and automate machine learning workflows. It integrates DevOps practices into machine learning workflows to streamline machine learning operations.&lt;/p&gt;
&lt;h3 id=&#34;why-do-we-need-mlops&#34;&gt;Why do we need MLOps?&lt;/h3&gt;
&lt;p&gt;Most of the time, as part of the machine learning workflow, they go through EDA, data prep, model training, tuning, then model deployment and monitoring just to find out that it is not ready for production. You have to repeat the process all over again and retrain the model.&lt;/p&gt;
&lt;p&gt;Since the machine learning workflows were manual and several teams were involved in this process at different stages, it took lot of time and effort to maintain it.&lt;/p&gt;
&lt;p&gt;Streamlining and automating such manual process speeds up time to product and decreases manual errors and risks. This leads to scalability of managing and monitoring thousands of machine learning models. This allows the data scientists and engineers to focus on model development and innovation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/mlops-diag.png&#34; alt=&#34;mlops-diagram&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;key-components-of-mlops&#34;&gt;Key components of MLOps&lt;/h3&gt;
&lt;p&gt;Machine learning lifecycle has several interconnected stages and all of these key components together make up MLOps. I have been going through various MLOps guides from AWS, Google, IBM and Databricks and realized all of them mostly follow the same key components.&lt;/p&gt;
&lt;h4 id=&#34;data-management&#34;&gt;Data Management&lt;/h4&gt;
&lt;p&gt;Data is the new oil. For ML data makes or breaks a model. It is the backbone of any machine learning model. Fetching right data, storage, preprocessing the data for model development and versioning are very important.&lt;/p&gt;
&lt;p&gt;Primarily this stage consists of Exploratory Data Analysis (EDA) which includes exploring and understanding data. Data preparation and feature engineering are also part of this step, which includes collecting data, processing data.&lt;/p&gt;
&lt;p&gt;Feature engineering preprocesses raw data into a machine-readable format. It optimizes ML model performance by transforming and selecting relevant features.&lt;/p&gt;
&lt;p&gt;Some MLOps implementations separate EDA and Data preparation into two stages.&lt;/p&gt;
&lt;p&gt;Here are some of the tools used for data management:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data versioning: Data Version Control (DVC), Delta Lake, MLflow.&lt;/li&gt;
&lt;li&gt;Data storage and management: Amazon S3, Google cloud storage, Azure Blob storage, Google BigQuery, Amazon RedShift, Snowflake&lt;/li&gt;
&lt;li&gt;Data Preparation: Apache Airflow, Databricks&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;model-development&#34;&gt;Model Development&lt;/h4&gt;
&lt;p&gt;This stage involves the design, training, tuning, and evaluation of machine learning models.&lt;/p&gt;
&lt;p&gt;Here are some of the tools and services used as part of model development:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Model development frameworks: Tensorflow / Keras, PyTorch, Scikit-learn&lt;/li&gt;
&lt;li&gt;Experiment tracking and Management: MLflow&lt;/li&gt;
&lt;li&gt;AutoML: Amazon SageMaker Autopilot, Google AutoML, Azure Machine Learning Studio&lt;/li&gt;
&lt;li&gt;IDEs: Jupyter Notebooks, R studio, VS Code, etc&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;model-deployment&#34;&gt;Model deployment&lt;/h4&gt;
&lt;p&gt;Focuses on packaging models, shipping them and deploying them to production environments. This step ensures the model is accessible via an API, microservice or application.&lt;/p&gt;
&lt;p&gt;Here are the tools and services used for model inferencing, serving and model deployment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Containers and Orchestration: KServe + Kubernetes platforms like Amazon EKS, GKE, Azure Kubernetes service.&lt;/li&gt;
&lt;li&gt;Managed model deployment services: Amazon Sagemaker, Google Vertex AI, Azure Machine Learning&lt;/li&gt;
&lt;li&gt;Model Serving: Kubeflow, TorchServe, TensorFlow Serving&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;model-inference-and-serving&#34;&gt;Model inference and serving&lt;/h4&gt;
&lt;p&gt;Model inference and serving involves making it available for use by applications and end users. It focuses on querying the deployed model to generate predictions.&lt;/p&gt;
&lt;p&gt;Services like Amazon SageMaker Endpoints, Google Vertex AI Endpoints, Azure Machine Learning Endpoints, TensorFlow Serving, KServe and MLflow Models are used.&lt;/p&gt;
&lt;h4 id=&#34;model-monitoring&#34;&gt;Model Monitoring&lt;/h4&gt;
&lt;p&gt;After deployment, continuous monitoring is essential to ensure that models perform as expected and maintain their accuracy over time.&lt;/p&gt;
&lt;p&gt;Prometheus + Grafana is the opensource stack for monitoring. Good to get started.
Model monitoring services: AWS SageMaker Model Monitor, Evidently. There are also custom monitoring solutions like Kubeflow pipelines.&lt;/p&gt;
&lt;h4 id=&#34;governance-and-compliance&#34;&gt;Governance and Compliance&lt;/h4&gt;
&lt;p&gt;This key component ensures ML models are developed and deployed responsibly and ethically.&lt;/p&gt;
&lt;p&gt;Model explainability can be done using Local Interpretable Model-agnostic Explanations (LIME) and SHAP (SHapley Additive exPlanations). MLflow supports Audit and compliance. Amazon Macie handles security. Data and Model Lineage can be done using MLflow, Amazon SageMaker Model Registry and Google Cloud Vertex AI Model Registry.&lt;/p&gt;
&lt;h4 id=&#34;automated-model-retraining&#34;&gt;Automated model retraining&lt;/h4&gt;
&lt;p&gt;Automated model retraining involves retraining the ML model when its performance degrades or when new data becomes available. In this stage model retraining is triggered when specific conditions are met, then retrain the model using latest data and then evaluate the retrained model.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;As the adoption of machine learning is sky rocketing, the importance of MLOps is now higher than ever. MLOps helps automate and streamline machine learning operations. I have tried listing some of the tools used in MLOps is every key component/stage of machine learning workflow. Which tools or services you choose for MLOps depends on whether you are running on AWS, Google, Azure, Databricks, baremetal or opensource. &lt;/p&gt;
&lt;p&gt;Hope this provided you with a good MLOps overview! What tools and services do you use in your MLOps?&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, AI/ML, EKS, Kubernetes, and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;references&#34;&gt;References&lt;/h4&gt;
&lt;p&gt;These are the references I used to learn and write this blog post.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MLOps from Google from google &lt;a href=&#34;https://cloud.google.com/discover/what-is-mlops&#34;&gt;https://cloud.google.com/discover/what-is-mlops&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MLOps from AWS &lt;a href=&#34;https://aws.amazon.com/what-is/mlops/&#34;&gt;https://aws.amazon.com/what-is/mlops/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MLOps from IBM &lt;a href=&#34;https://www.ibm.com/think/topics/mlops&#34;&gt;https://www.ibm.com/think/topics/mlops&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MLOps from Databricks &lt;a href=&#34;https://www.databricks.com/glossary/mlops&#34;&gt;https://www.databricks.com/glossary/mlops&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Practitioners Guide to Machine Learning Operations (MLOps) &lt;a href=&#34;https://cloud.google.com/resources/mlops-whitepaper&#34;&gt;https://cloud.google.com/resources/mlops-whitepaper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Pod Disruption Budget vs NodePool Disruption Budget?</title>
      <link>https://vijay.eu/posts/pod-disruption-budget-vs-nodepool-disruption-budget/</link>
      <pubDate>Sun, 02 Mar 2025 23:45:23 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/pod-disruption-budget-vs-nodepool-disruption-budget/</guid>
      <description>&lt;p&gt;In Kubernetes, managing downtimes is very critical to maintain High Availability. &lt;strong&gt;Pod Disruption Budget&lt;/strong&gt; (PDB in short) and &lt;strong&gt;NodePool Disruption Budget&lt;/strong&gt; (NDB in short) plays an important role in managing high availability at different layers of Kubernetes.&lt;/p&gt;
&lt;p&gt;PDBs ensure that a minimum number of application pods are running when one or more nodes are disrupted voluntarily, for example during cluster upgrades, node drain etc.&lt;/p&gt;
&lt;p&gt;You can set pdb value to either &amp;ldquo;&lt;code&gt;minAvailable&lt;/code&gt;&amp;rdquo; or &amp;ldquo;&lt;code&gt;maxUnavailable&lt;/code&gt;&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Here are some example usages of PDB:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;By setting &amp;ldquo;&lt;code&gt;minAvailable&lt;/code&gt;&amp;rdquo; to quorum size of 3 when scale is 5 for an etcd cluster, you make sure etcd pods do not reduce below quorum thus keeping the writes from failing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you only run single replica of your application pod and you don&amp;rsquo;t want voluntary disruptions to terminate the application then set &amp;ldquo;&lt;code&gt;maxUnavailable=0&lt;/code&gt;&amp;rdquo;.  In this case, you have to manually evict the pod. This allows you to plan for downtime and then delete the pod manually.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PDBs help prevent downtime by ensuring enough replicas are running when the nodes are down voluntarily.&lt;/p&gt;
&lt;p&gt;Check the popular statefulsets to see how they have configured pdb in their K8s yamls. Here is one such &lt;a href=&#34;https://github.com/strimzi/strimzi-kafka-operator/blob/main/install/cluster-operator/040-Crd-kafka.yaml#L3241&#34;&gt;example&lt;/a&gt; from strimzi-kafka-operator.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NodePool Disruption Budgets&lt;/strong&gt; (NDB) controls how many nodes in a node pool can be disrupted simultaneously, e.g., during rolling updates, Karpenter autoscaling etc.&lt;/p&gt;
&lt;p&gt;NodePools and NDBs are part of Karpenter and you must have Karpenter installed in your Kubernetes cluster before configuring NDBs.&lt;/p&gt;
&lt;p&gt;Karpenter uses NDBs to rate limit Karpenter&amp;rsquo;s disruption. If undefined, it defaults to &amp;ldquo;node:10%&amp;rdquo;. NDBs do not prevent Karpenter from terminating  expired nodes.&lt;/p&gt;
&lt;p&gt;Examples of NDB:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;&lt;code&gt;spec.disruption.budgets.nodes: 10%&lt;/code&gt;&amp;rdquo; will only allow 10% nodes in that nodepool to be disrupted. You can add reasons like &amp;ldquo;if nodes are Empty&amp;rdquo; along with 10% limit.&lt;/li&gt;
&lt;li&gt;Another example for NDB would be to block node disruption first hour during the day for underutilized nodes using:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;     - nodes: &amp;#34;0&amp;#34;
        schedule: &amp;#34;@daily&amp;#34;
        duration: 1h
        reasons:
        - &amp;#34;Underutilized&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can attach multiple budgets to the same NDB.&lt;/p&gt;
&lt;p&gt;Set &amp;ldquo;&lt;code&gt;karpenter.sh/do-not-disrupt: true&lt;/code&gt;&amp;rdquo; to block Karpenter from voluntarily choosing you pod, Deployment, Node or NodePool. Note that setting this annotation does not prevent nodes from forceful disruptions like Expiration, Node Repair etc.&lt;/p&gt;
&lt;p&gt;As you can see in this below diagram, PDB is attached to specific set of pods using a label selector &lt;code&gt;.spec.selector&lt;/code&gt;. You add NDB budget in the NodeClass YAML.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/pdb-ndb-v1.png&#34; alt=&#34;PDB vs NDB&#34;&gt;&lt;/p&gt;
&lt;p&gt;To summarize, use PDB to maintain availability of critical application pods and use NDB to limit disruptions at nodepool level. By combining both, you can increase your pod availability and cluster stability.&lt;/p&gt;
&lt;p&gt;Do you use PDB or NDB? Share your experience in my &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7302022325053353984/&#34;&gt;LinkedIn post&lt;/a&gt; comments!&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Classic Snake Game using LLMs</title>
      <link>https://vijay.eu/posts/snake-game/</link>
      <pubDate>Sun, 16 Feb 2025 23:23:47 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/snake-game/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/SnakeRedApple.jpeg&#34; alt=&#34;snake&#34;&gt;
Image Credit: Generated using Google Imagen3.&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;Last August, I have spent a week trying to create working applications using GenAI models. These were meant to be useful for me and my kids and to assess the capabilities of the then popular LLMs like ChatGPT, Claude, and Gemini. You can find them here &lt;a href=&#34;https://vijay.eu/projects/&#34;&gt;https://vijay.eu/projects/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;my-initial-experience&#34;&gt;My initial experience&lt;/h2&gt;
&lt;p&gt;This was my experience back then: Ask each LLM to generate code for a project, copy the code into local files, test it locally, come up with new suggestions and then rinse and repeat until I found the project working well as per my expectation.&lt;/p&gt;
&lt;p&gt;For this exercise I have used: Anthropic Claude, Google Gemini, and OpenAI ChatGPT.
Each had a different way of generating code, handling code changes on top of existing code and updating code.&lt;/p&gt;
&lt;p&gt;From my experience at that time, Anthropic Claude understood prompts really well and generated code much better than all other LLMs. The quality of code was way better than others. One major advantage was Claude Artifacts. This was a deal breaker for me and game changer for testing quick prototypes in the chat window itself. Also Claude allowed you to host the code and gave you an URL to share with your friends. Getting the html files and testing locally also worked seemlessly. It let you download the files. No copy pasting code from the chat window, which was the case for the remaining two LLMs.&lt;/p&gt;
&lt;h2 id=&#34;new-challenge&#34;&gt;New Challenge&lt;/h2&gt;
&lt;p&gt;Then came the other challenge. My website(&lt;a href=&#34;https://vijay.eu&#34;&gt;https://vijay.eu&lt;/a&gt;) is based on Hugo and it is a static website hosted on GitHub Pages. GitHub delivers the static webpages to your mobile/computer when you open my website. There is no dynamic content in my website so there is no need of backend server to process the requests.&lt;/p&gt;
&lt;p&gt;I wanted to host my projects created using LLMs also on my website. This means, those projects should be fully static and should not require a backend server to handle any requests for the frontend running in user&amp;rsquo;s mobile or computer.&lt;/p&gt;
&lt;p&gt;Hugo uses templating which simplifies adding new posts, which means all posts have the same header, footer, common javascript and common CSS. However for my projects, most of the magic is handled as part of Javascript and CSS.&lt;/p&gt;
&lt;p&gt;I spent several hours tweaking the code, explaining this to LLMs and asking them to generate the code which works with my existing hugo code. This took quite an effort and took several trial and errors before the first project worked. When I wanted to create a second flag game I had to do all this over again as it included a different design and there were upto ten questions each coming one after another. I enjoyed building those games but thought these should have been handled automatically for me.&lt;/p&gt;
&lt;h2 id=&#34;current-experience-with-llms&#34;&gt;Current experience with LLMs&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Today after four months&lt;/strong&gt;, I wanted to check how far these LLMs have improved. So I decided to create classic snake game for my kids to play. Asked the same prompt to Claude, Gemini and ChatGPT. ChatGPT has new feature similar to Claude&amp;rsquo;s artifact. ChatGPT created the code and displayed the code and demo window. When I pressed Preview, it kinda worked until the green snake (a single green square) ate the first red square. After that it all went haywire. There were multiple red squares appearing randomly across the box and the green square does not move.&lt;/p&gt;
&lt;p&gt;Gemini generated code in a window and no option to run locally in the window. Copied the code to my computer and ran it locally. It didn&amp;rsquo;t work. There was a black box and nothing else. No red or green squares.&lt;/p&gt;
&lt;p&gt;Now, Claude generated perfectly working code, tested it in the artifact window and also customized the code to work with my hugo website. It also gave me instructions to add shortcodes in my hugo to add new javascript and css for this game. I felt the snake was moving too fast and asked Claude to generate new version to add three different speeds. It did on first try. I have tested it locally then added it my blog and pushed the changes. You can try this snake game on my website at &lt;a href=&#34;https://vijay.eu/projects/snake-game/&#34;&gt;https://vijay.eu/projects/snake-game/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;winner-this-time&#34;&gt;Winner this time&lt;/h3&gt;
&lt;p&gt;So, in this second round of my game benchmarking of LLMs, the winner is &lt;strong&gt;Anthropic Claude&lt;/strong&gt; :)&lt;/p&gt;
&lt;h2 id=&#34;my-thoughts&#34;&gt;My Thoughts&lt;/h2&gt;
&lt;p&gt;These LLMs are now getting more advanced, producing error free code and understanding user prompts much better. This took me 10 minutes to prompt, test, download and push it to my website. TEN minutes from getting the idea to publishing it live on my website. This is A-W-E-S-O-M-E. You just have to imagine and you have unlimited digital workers, a.k.a LLMs, realizing those dreams for you. Democratizing code for everyone. This gives more power to people who can create end-to-end projects from idea to design to code to deploying it in real world production.&lt;/p&gt;
&lt;p&gt;How was your experience working with LLMs? What difference have you observed over the last six months?&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hands-on Bedrock Agents workshop</title>
      <link>https://vijay.eu/posts/bedrock-agents-workshop/</link>
      <pubDate>Sat, 15 Feb 2025 00:22:33 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/bedrock-agents-workshop/</guid>
      <description>&lt;p&gt;Are agents the missing piece for LLMs to super-charge real-world adoption? Today, I had the opportunity to attend AWS Immersion Day at AWS Helsinki office and try hands-on workshop on Agents, RAG, and more.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/bedrock-ws-1.jpeg&#34; alt=&#34;bedrock-workshop&#34;&gt;&lt;/p&gt;
&lt;p&gt;Thanks Amazon Web Services (AWS), Ankit Nigam, Kimmo Isosomppi, Heidi Tähtinen, Ezaldeen Arafat for organizing this workshop. This was immensely useful and improved my understanding of Agents, RAG, Guardrails and inference.&lt;/p&gt;
&lt;p&gt;As part of the hands-on workshop, I have created a mortage-processing-agent which uses RAG to add domain specific knowledge base and then created agents which can determine if end-user can afford it based on their financial situation.
After that, created Amazon Bedrock Flows that orchestrates entire workflow. Last but not the least, created Guardrails to implement safeguards and enforce responsible AI policies for my GenAI application.&lt;/p&gt;
&lt;p&gt;Here is the mortgage processing agent I built during the hands-on workshop.
The highlighted yellow box is the prompt user enters followed by the response from Bedrock.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/bedrock-ws-handson.jpeg&#34; alt=&#34;bedrock-handson&#34;&gt;&lt;/p&gt;
&lt;p&gt;All in all, this was a very good way to get hands-on experience on Amazon Bedrock Agents, RAG, Flows and Guardrails.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/bedrock-ws-agents.jpeg&#34; alt=&#34;bedrock-agents&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Presented on EKS Auto Mode at the AWS Helsinki Meetup</title>
      <link>https://vijay.eu/posts/presented-at-aws-meetup/</link>
      <pubDate>Thu, 06 Feb 2025 20:17:49 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/presented-at-aws-meetup/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/aws-meetup-1.png&#34; alt=&#34;AWS Meetup Presenting&#34;&gt;&lt;/p&gt;
&lt;p&gt;Had an amazing time presenting at the AWS meetup today! It was great to share my insights on how EKS Auto mode can help the customers get rid off undifferentiated heavy lifting.&lt;/p&gt;
&lt;p&gt;Started with the basics of Kubernetes for those new to it and then went on to explain how EKS helps customers and how EKS Auto mode will simplify K8s Day 2 operations. The lively Q&amp;amp;A was a highlight, and I learned a lot from the audience&amp;rsquo;s perspectives.  Public speaking is a journey, and I&amp;rsquo;m grateful for the opportunity to practice and grow.&lt;/p&gt;
&lt;p&gt;A huge thank you to Petri Rosenström, Rolf Koski and Accenture for organizing the Amazon Web Services (AWS) meetup today in Helsinki.&lt;/p&gt;
&lt;p&gt;Also learnt about Accenture&amp;rsquo;s technology vision from Juha Takala, Emil Nyback and interesting GenAI talk from Niklas Liljestrand !!! All great talks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/aws-meetup-2.png&#34; alt=&#34;AWS Meetup Presenting 2&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Running Deepseek R1 locally</title>
      <link>https://vijay.eu/posts/running-deepseek-locally/</link>
      <pubDate>Wed, 29 Jan 2025 22:12:06 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/running-deepseek-locally/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/snowdrop.png&#34; alt=&#34;snowdrop&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here is a video of Deepseek R1 running locally on my Macbook.
Now that everyone is amazed by the low level of resource utilization and open weight model of Deepseek R1, installed 8B model locally.&lt;/p&gt;
&lt;p&gt;With the help of ollama it is as simple as running a single command -
&amp;ldquo;ollama run deepseek-r1:8b&amp;rdquo;
You get your own private, local LLM running securely in your computer.&lt;/p&gt;
&lt;p&gt;My prompt is &amp;ldquo;Generate a five line fairy tale about AI?&amp;rdquo;. In the video, you can see how before generating the response, it thinks. Thinking text is in between &lt;!-- raw HTML omitted --&gt; and &lt;!-- raw HTML omitted --&gt; tags.&lt;/p&gt;
&lt;p&gt;Watch the video to read the five line fairy tale about AI.&lt;/p&gt;
&lt;p&gt;Do you have any experience running Deepseek R1?&lt;/p&gt;
&lt;iframe 
  src=&#34;https://www.youtube.com/embed/CYfpgvsTG9E?si=QKfJcJB1vjJIRWwe&#34; 
  width=&#34;560&#34; 
  height=&#34;315&#34; 
  title=&#34;Embedded Content&#34; 
  frameborder=&#34;0&#34; 
  allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; 
  referrerpolicy=&#34;strict-origin-when-cross-origin&#34;
  allowfullscreen&gt;
&lt;/iframe&gt;

&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New metric to measure the efficiency of AI models</title>
      <link>https://vijay.eu/posts/new-llm-metric/</link>
      <pubDate>Tue, 28 Jan 2025 20:03:20 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/new-llm-metric/</guid>
      <description>&lt;p&gt;At the end of the day, how cheaply and energy efficiently can you generate tokens matters.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;&lt;strong&gt;Tokens per watt per dollar&lt;/strong&gt;&amp;rdquo; metric mentioned by Satya Nadella, CEO of Microsoft, is trying to achieve the same.&lt;/p&gt;
&lt;p&gt;This will be a metric by which every LLM is going to be benchmarked against. This is the metric which will showcase how long can an AI investment lasts and how much is your profitability of AI startups.&lt;/p&gt;
&lt;p&gt;There will be a comparison of LLMs with &amp;ldquo;Tokens per watt per dollar&amp;rdquo; soon, if not already existing.&lt;/p&gt;
&lt;p&gt;I would love to hear your thoughts on this?&lt;/p&gt;
&lt;p&gt;This is &lt;a href=&#34;https://www.linkedin.com/posts/satyanadella_wef25-activity-7287900710770196480-7mn6/&#34;&gt;related post&lt;/a&gt; by Satya.&lt;/p&gt;
&lt;p&gt;If you have not already watched, highly recommend Satya Nadella&amp;rsquo;s &lt;a href=&#34;https://www.youtube.com/watch?v=kOkDTvsUuWA&amp;amp;t=156s&#34;&gt;AI Tour Keynote: London&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>This new EventBridge capability simplifies your cross-account deployments</title>
      <link>https://vijay.eu/posts/eventbridge-new-capability/</link>
      <pubDate>Wed, 22 Jan 2025 12:12:42 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/eventbridge-new-capability/</guid>
      <description>&lt;p&gt;This new capability in &lt;strong&gt;EventBridge&lt;/strong&gt; is going to simplify your cross-account &lt;strong&gt;Event Driven Architecture&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;AWS introduced cross account targets for EventBridge event buses today. Now you can add &lt;strong&gt;SQS&lt;/strong&gt;, &lt;strong&gt;Lambda&lt;/strong&gt; or &lt;strong&gt;SNS&lt;/strong&gt; as targets from a different account. Previously only EventBridge in another account could be added.&lt;/p&gt;
&lt;p&gt;The architecture diagram from the AWS blog is attached in this post. It perfectly captures everything you need to know about this feature.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/eventbridge1.jpg&#34; alt=&#34;AWS Event Bridge&#34;&gt;&lt;/p&gt;
&lt;p&gt;Remember to do these two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add relevant execution &amp;ldquo;role&amp;rdquo; in source AWS account EventBridge rule.&lt;/li&gt;
&lt;li&gt;Apply &amp;ldquo;resource policy&amp;rdquo; to SQS/SNS/Lambda in the Target Account.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Role&amp;rdquo;&lt;/strong&gt; for Source Account and &lt;strong&gt;&amp;ldquo;Resource policy&amp;rdquo;&lt;/strong&gt; for Target account. Everything else is same as before.&lt;/p&gt;
&lt;p&gt;This makes sure security is taken care from both Source and Target AWS accounts and avoids any abuse or DDoS situations.&lt;/p&gt;
&lt;p&gt;Read the AWS Blog &lt;a href=&#34;https://aws.amazon.com/blogs/compute/introducing-cross-account-targets-for-amazon-eventbridge-event-buses/&#34;&gt;post here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Surprising side effect of running EKS Auto Mode</title>
      <link>https://vijay.eu/posts/surprising-side-effect-eks-auto/</link>
      <pubDate>Tue, 21 Jan 2025 12:10:31 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/surprising-side-effect-eks-auto/</guid>
      <description>&lt;p&gt;One surprising side effect you will notice when you move to EKS Auto mode is that you cannot create a Classic Load Balancer (CLB) using Kubernetes Service annotations. You can only create Network Load Balancers (NLB) using K8s Service annotations.&lt;/p&gt;
&lt;p&gt;This restriction came into place due to the automatic inclusion of AWS Load Balancer controller as an add-on in EKS Auto mode. AFAIK, there is no way to disable or remove that add-on from EKS Auto mode cluster.&lt;/p&gt;
&lt;p&gt;If you are utilizing other ingress controllers like HAProxy, then you cannot create a CLB (HTTPS) using Service annotations. You can only create NLBs using Service annotations and route the traffic through HAProxy ingress controller. After that you can create ingresses which can utilize HAProxy as ingress controller.&lt;/p&gt;
&lt;p&gt;This means that if you have been using HAProxy ingress controller or other similar ingress controllers then this limitation restricts you to service HTTP/HTTPS traffic through them.&lt;/p&gt;
&lt;p&gt;Since this is a new release, I haven&amp;rsquo;t seen any update in their docs. I am curious on how other ingress controllers handle this change.&lt;/p&gt;
&lt;p&gt;Have you faced this issue in EKS Auto mode? Did you manage to fix it? I would like to know your thoughts on this?&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Have you seen multi-session support enabled in your AWS Console?</title>
      <link>https://vijay.eu/posts/multi-sessions-in-aws-console/</link>
      <pubDate>Thu, 16 Jan 2025 11:47:06 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/multi-sessions-in-aws-console/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/multisess.png&#34; alt=&#34;multisession&#34;&gt;
Image: Image shows the multi-session support enabled in my AWS Console.&lt;/p&gt;
&lt;p&gt;Observed it today morning that multi-session support is enabled in my AWS account.&lt;/p&gt;
&lt;p&gt;This feature saves lot of effort and time for me. I work with different AWS accounts and logging into those AWS consoles or switching between them is an extra step. Usually I use different browsers to keep both AWS console logins active but it increases CPU/memory load on my PC.&lt;/p&gt;
&lt;p&gt;Now I can use single browser and login to two different accounts simultaneously. Saves CPU/RAM in my PC as I don&amp;rsquo;t have to run two browsers now.&lt;/p&gt;
&lt;p&gt;AWS manages this by adding unique account specific URLs to identify which account you are in even though you access the same EC2 or EKS service in both accounts.&lt;/p&gt;
&lt;p&gt;This is a big feature for me from usability perspective. Currently this is being rolled out and is available only for limited number of user accounts.&lt;/p&gt;
&lt;p&gt;Watch out for this feature in your AWS account and give it a try!!!&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Do you run your database on Kubernetes?</title>
      <link>https://vijay.eu/posts/database-on-kubernetes/</link>
      <pubDate>Fri, 10 Jan 2025 11:34:54 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/database-on-kubernetes/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/dbink8s.webp&#34; alt=&#34;dbink8s&#34;&gt;&lt;/p&gt;
&lt;p&gt;Do you run your database on Kubernetes? This has been an evergreen debate. Where does it stand now?&lt;/p&gt;
&lt;p&gt;Kubernetes has come a long way from running only stateless workloads early on to now supporting statefulsets with improvements in sticky identity, persistent storage and unique network identity. Kubernetes has democratized the container orchestration and given the world tools to run most software at scale. This is only one part of the solution.&lt;/p&gt;
&lt;p&gt;Databases built to run directly on servers or virtual machines have different features to make them highly available, resilient and scalable. Now if you bring those databases and run them on Kubernetes then it is a recipe for disaster. In the recent years, there have been cloud native databases built to run on Kubernetes. This is the remaining part of the solution.&lt;/p&gt;
&lt;p&gt;You have a container orchestrator platform like Kubernetes which runs most of your software and now with cloud-native databases, you can run them on Kubernetes too.&lt;/p&gt;
&lt;p&gt;Best of both worlds? What about latency? How do you handle frequent k8s release upgrades every three months? Now with EKS Auto mode, the worker nodes max lifetime is just 21 days. Imagine moving around your database nodes every two-three weeks? Is it recommended in production? Do you instead use managed database service from hashtag#AWS hashtag#GoogleCloud or hashtag#Azure?&lt;/p&gt;
&lt;p&gt;There is no right or wrong answer and &amp;ldquo;It Depends&amp;rdquo; on the software architecture and business constraints.&lt;/p&gt;
&lt;p&gt;I would like to hear from you all. Write your opinion in the comments below. Do you run your database on Kubernetes? Why? Why not? What are your reasons? Are you using it in production? What is the adoption for such databases?&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Image generated using DALL.E to depict storage in the cloud.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What is ARC Zonal shift feature in EKS?</title>
      <link>https://vijay.eu/posts/eks-arc-zonal-shift/</link>
      <pubDate>Mon, 30 Dec 2024 01:04:17 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/eks-arc-zonal-shift/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/snowdrop.png&#34; alt=&#34;snowdrop&#34;&gt;
&lt;em&gt;Image Credits:&lt;/em&gt; Generated using DALL.E. &lt;em&gt;This image depicts &lt;strong&gt;resiliency&lt;/strong&gt; in nature similar to what is expected from your AWS architecture :)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Recently I have created an EKS Auto mode cluster and observed that &lt;strong&gt;“ARC Zonal shift”&lt;/strong&gt; feature was enabled for my EKS cluster.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Amazon Application Recovery Controller (ARC)&lt;/strong&gt; helps simplify and automate recovery for highly available applications. It was initially known as “Route 53 ARC” and since then has expanded to support Amazon EC2 Auto scaling groups, ALB, NLB and now EKS. So it is now just Amazon ARC.&lt;/p&gt;
&lt;p&gt;You can recover from an impaired Availability Zone (AZ) using ARC Zonal Shift and Zonal autoshift. Zonal shift is used when you manually trigger it to shift traffic away from an impaired AZ. Use Zonal autoshift to let AWS monitor and shift traffic on your behalf.&lt;/p&gt;
&lt;p&gt;If you want to run resilient and highly available applications across multi-AZs in EKS and you want to survive an AZ going down then this is the feature (EKS Zonal Shift) you need.&lt;/p&gt;
&lt;p&gt;Remember that this will only redirect internal east-west traffic inside your EKS traffic between your pods. If you want to redirect traffic from loadbalancers similarly then you have to enable an ALB or NLB with ARC Zonal shift.&lt;/p&gt;
&lt;p&gt;Performing a zonal shift enables you to achieve rapid recovery from application failures in a single Availability Zone (AZ). This is helpful to build resilience in case of an AZ impairment or when an AZ is down.&lt;/p&gt;
&lt;p&gt;You can enable it from EKS cluster creation step or enable it afterwards for already running clusters. If you are creating EKS auto mode cluster with “Quick configuration” option then ARC Zonal shift is enabled by default.&lt;/p&gt;
&lt;p&gt;With zonal shift, you can temporarily mitigate issues and incidents by triggering a shift and redirecting in-cluster network traffic to a healthy AZ.&lt;/p&gt;
&lt;p&gt;For this to work, you should already be running EKS worker nodes in multiple AZs (at least three) for HA and resiliency and your applications are already running in multiple AZs. So if your application is already running in three different AZs and if one AZ is impaired then Zonal shift will redirect traffic away from impaired AZ to healthy AZs. In this case, you will have your application running in two AZs as highly available after the third one went down.&lt;/p&gt;
&lt;p&gt;Ideally such setup comes with cost so use it for highly critical workloads where you need such level of high-availability and resiliency.&lt;/p&gt;
&lt;p&gt;Check the EKS Zonal shift documentation to learn more: &lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/zone-shift.html&#34;&gt;https://docs.aws.amazon.com/eks/latest/userguide/zone-shift.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Follow me on LinkedIn for more content related to Kubernetes, EKS and AWS in general. Visit my website at &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;https://vijay.eu/posts&lt;/a&gt; for all my posts in one place.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Do you know that EKS Auto Mode enforces a 21-day maximum node lifetime?</title>
      <link>https://vijay.eu/posts/eks-auto-max-node-lifetime/</link>
      <pubDate>Thu, 12 Dec 2024 14:13:02 +0530</pubDate>
      
      <guid>https://vijay.eu/posts/eks-auto-max-node-lifetime/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/EKS-Auto-Mode.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;Do you know that EKS Auto Mode enforces a 21-day maximum node lifetime?&lt;/p&gt;
&lt;p&gt;EKS Auto mode cluster manages worker nodes on your behalf.
Karpenter deletes worker nodes in EKS auto mode nodepools after 21 days of node lifetime. This is the maximum node lifetime. It will be replaced with a new node.&lt;/p&gt;
&lt;p&gt;This is needed for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;providing security patches&lt;/li&gt;
&lt;li&gt;OS updates&lt;/li&gt;
&lt;li&gt;component upgrades&lt;/li&gt;
&lt;li&gt;improves security posture&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-if-you-want-to-modify-the-maximum-node-lifetime&#34;&gt;What if you want to modify the maximum node lifetime?&lt;/h2&gt;
&lt;p&gt;You can reduce the maximum node lifetime by creating a custom NodePool with “spec.template.spec.expireAfter” with a value of node lifetime in hours. Max is 21 days.&lt;/p&gt;
&lt;h2 id=&#34;how-to-disable-it&#34;&gt;How to disable it?&lt;/h2&gt;
&lt;p&gt;If for some reason, you do not want to delete worker nodes so frequent or if you want to keep the nodes static then you can create a new Managed Node Group and add nodes in it.
You can create both EKS Auto mode nodepools and Managed Node groups (without auto mode) in the same EKS cluster. These are called mixed-mode clusters.
I will be covering more about mixed-mode clusters in future posts.&lt;/p&gt;
&lt;p&gt;For more insights on EKS, AWS, Kubernetes, and Cloud Architecture, follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and check out &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt; for all my blog posts in one place.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>First Impressions of EKS Auto Mode – A Game Changer!</title>
      <link>https://vijay.eu/posts/eks-auto-first-impressions/</link>
      <pubDate>Wed, 04 Dec 2024 23:13:15 +0530</pubDate>
      
      <guid>https://vijay.eu/posts/eks-auto-first-impressions/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/aws-eks-pic.png&#34; alt=&#34;Kubernetes&#34;&gt;
&lt;em&gt;Image Credit: From AWS EKS Blog&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Here are my thoughts after initial few days of using &lt;strong&gt;EKS Auto mode&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;AWS has truly raised the bar with EKS Auto Mode, a new feature announced at &lt;strong&gt;re:Invent 2024&lt;/strong&gt;. This innovation automates much of the undifferentiated heavy lifting, allowing customers to focus on what matters most: building great applications.&lt;/p&gt;
&lt;h2 id=&#34;my-hands-on-experience&#34;&gt;My Hands-On Experience&lt;/h2&gt;
&lt;p&gt;I set up an EKS Auto Mode cluster from scratch and was pleasantly surprised by how much AWS now handles post-installation. You can read in &lt;a href=&#34;https://www.linkedin.com/pulse/how-create-eks-auto-mode-cluster-vijay-kumar-kodam-oqw4f/&#34;&gt;more detail about it here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let me break down what &lt;em&gt;Day 2 operations&lt;/em&gt; typically involve:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Managed Node Groups&lt;/strong&gt;: Create managed node groups and wait for worker nodes to come up.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;EKS Node capabilities&lt;/strong&gt;: Most of them were running as Kubernetes Daemonsets on worker nodes before. Now they run as system processes managed by AWS. This includes components such as service discovery, service load balancing, pod networking, block storage, and credential vending.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add-Ons Installation&lt;/strong&gt;: Select and install versions for multiple EKS add-ons (latest, standard, or older). Like coredns, EBS CSI driver, CNI driver, EKS pod identity etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Load Balancer Controller&lt;/strong&gt;: Install the AWS Load Balancer Controller for ingress traffic handling.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cost Optimization&lt;/strong&gt;: Install Karpenter to manage pod bin-packing, scale nodes dynamically, and select cost-efficient EC2 instances.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OS Security patching&lt;/strong&gt;: Address OS security vulnerabilities identified by AWS Security Hub.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cluster Upgrades&lt;/strong&gt;: Over time, you need to upgrade Kubernetes control plane versions and meticulously plan worker node updates. This is a continuous process every 3-6 months.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, imagine all these tasks being automated by AWS. That’s EKS Auto Mode for you!&lt;/p&gt;
&lt;h2 id=&#34;key-highlights-from-my-testing&#34;&gt;Key Highlights from My Testing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;No Idle Nodes&lt;/strong&gt;: When I launched my first EKS Auto Mode cluster, there were no worker nodes running initially—just built-in &amp;ldquo;general-purpose&amp;rdquo; and &amp;ldquo;system&amp;rdquo; node pools.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dynamic Scaling&lt;/strong&gt;: After deploying my first application, Karpenter automatically spun up a worker node tailored to the app&amp;rsquo;s resource requirements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cost Efficiency&lt;/strong&gt;: Upon deleting the application, Karpenter scaled down the node, saving money by avoiding idle resources.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This level of automation simplifies cluster operations and significantly reduces costs.&lt;/p&gt;
&lt;h2 id=&#34;pricing-update&#34;&gt;Pricing Update&lt;/h2&gt;
&lt;p&gt;EKS Auto Mode introduces a pay-as-you-go control plane pricing model based on the number of EC2 worker nodes, a shift from the flat fee for the standard EKS control plane. While it’s a slight increase in cost, the time and effort saved make it a Win-Win for both AWS and customers. Find more about &lt;a href=&#34;https://aws.amazon.com/eks/pricing/&#34;&gt;EKS Auto mode pricing here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What’s Next?&lt;/h2&gt;
&lt;p&gt;I’ve &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7269311743338663936/&#34;&gt;created a demo video&lt;/a&gt; showcasing EKS Auto Mode in action. If you’re curious, I highly recommend giving this feature a try!&lt;/p&gt;
&lt;p&gt;For more insights on EKS, AWS, Kubernetes, and Cloud Architecture, follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; or check out my blog at &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;https://vijay.eu/posts&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let me know your thoughts on this exciting new feature! 👇&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to secure microservices architecture in AWS?</title>
      <link>https://vijay.eu/posts/aws-secure-microservices/</link>
      <pubDate>Mon, 04 Nov 2024 00:06:59 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/aws-secure-microservices/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/ms-secure.png&#34; alt=&#34;aws-security&#34;&gt;
&lt;strong&gt;Image Credits:&lt;/strong&gt; Microservices architecture image made by me using draw.io&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Security in Public Cloud is utmost important. Losing access to your website or attackers deleting your database are catastrophic-company-ending-events.&lt;/p&gt;
&lt;h3 id=&#34;shared-responsibility-model&#34;&gt;Shared Responsibility Model&lt;/h3&gt;
&lt;p&gt;Security and Compliance is a shared responsibility between AWS and the customer.&lt;/p&gt;
&lt;p&gt;Here is the definition from AWS documentation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;AWS is responsible for the &lt;strong&gt;&amp;ldquo;Security of the Cloud&amp;rdquo;&lt;/strong&gt;. AWS is responsible for protecting the infrastructure that runs all of the services offered in the AWS Cloud. This infrastructure is composed of the hardware, software, networking, and facilities that run AWS Cloud services.&lt;/p&gt;
&lt;p&gt;Customer is responsible for the &lt;strong&gt;“Security in the Cloud”&lt;/strong&gt;. Customer responsibility will be determined by the AWS Cloud services that a customer selects. This determines the amount of configuration work the customer must perform as part of their security responsibilities.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Refer AWS Documentation for more information on Shared Responsibility Model.&lt;/p&gt;
&lt;h3 id=&#34;best-practices&#34;&gt;Best Practices&lt;/h3&gt;
&lt;p&gt;Luckily, AWS provides you with a host of security services to improve your security posture from Day One. Note that this is not an exhaustive list and &amp;ldquo;it depends&amp;rdquo; on where you run and what services you use. Here are some of the steps to secure your microservices architecture in AWS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use AWS Shield for DDoS protection&lt;/li&gt;
&lt;li&gt;Use AWS GuardDuty for intelligent threat detection.&lt;/li&gt;
&lt;li&gt;Use AWS IAM for managing identities and access to AWS resources&lt;/li&gt;
&lt;li&gt;Use AWS WAF to protect your web applications from common exploits.&lt;/li&gt;
&lt;li&gt;Use AWS Certificates Manager for encrypting website data in transit using TLS/SSL certificates.&lt;/li&gt;
&lt;li&gt;Use AWS KMS keys to encrypt all EBS volumes and Aurora DB (data at rest)&lt;/li&gt;
&lt;li&gt;Use AWS Secrets Manager to store your application secrets.&lt;/li&gt;
&lt;li&gt;Run all your workloads in private subnets. Allow only needed traffic using Security Groups and NACLs.&lt;/li&gt;
&lt;li&gt;If your applications need Internet connectivity to download updates then configure NAT GW in public subnet.&lt;/li&gt;
&lt;li&gt;You could also use VPC peering to isolate specific workloads in a different VPC in a different AWS account.&lt;/li&gt;
&lt;li&gt;Use Amazon Inspector to scan EC2 for security vulnerabilities&lt;/li&gt;
&lt;li&gt;Use Amazon Security Hub to automate AWS security checks and centralize security alerts.&lt;/li&gt;
&lt;li&gt;Use AWS Cognito for authentication and authorization of the API requests.&lt;/li&gt;
&lt;li&gt;Use CloudTrail for audit logging.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Security should not be an after thought when building and running applications in AWS. Utilize some or all of these AWS security services to make your microservices architecture secure.&lt;/p&gt;
&lt;p&gt;What have I missed? This post assumed microservices are running in EC2 VMs. If microservices are running in Amazon EKS then it calls for a totally new approach and very long post. I will post about EKS security soon.&lt;/p&gt;
&lt;p&gt;Follow me on LinkedIn at &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;https://www.linkedin.com/in/vijaykodam/&lt;/a&gt; where I post articles about AWS, Kubernetes and cloud computing in general. I also post all my articles to my blog at &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;https://vijay.eu/posts&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Save Hours During Amazon EKS Upgrades with This One Simple Step!</title>
      <link>https://vijay.eu/posts/eks-upgrade-insights/</link>
      <pubDate>Thu, 03 Oct 2024 01:00:19 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/eks-upgrade-insights/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/K8s.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;🚀 Save Hours During Amazon EKS Upgrades with This One Simple Step! 🚀&lt;/p&gt;
&lt;p&gt;If you’ve ever managed EKS clusters in production, you know how crucial it is to keep them updated to leverage the latest features and maintain security.&lt;/p&gt;
&lt;p&gt;🔄 But before starting an upgrade, have you checked the &amp;ldquo;Upgrade Insights&amp;rdquo; tab on the EKS cluster page?&lt;/p&gt;
&lt;p&gt;Previously, our team had to manually check for deprecations and potential issues before every upgrade, spending hours in the process. Now, with the &amp;ldquo;Upgrade Insights&amp;rdquo; feature, EKS continuously monitors audit logs, detects deprecation errors, and updates the insights daily.&lt;/p&gt;
&lt;p&gt;This small step has transformed our process and saved us countless hours of debugging and maintenance. 💡&lt;/p&gt;
&lt;p&gt;✅ &lt;strong&gt;Pro tip&lt;/strong&gt;: Always review the &amp;ldquo;Upgrade Insights&amp;rdquo; tab before upgrading your clusters to ensure a smooth transition to newer Kubernetes versions.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback by commenting on my LinkedIn post below.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/posts/activity-7247354293660356609-IT7t&#34;&gt;https://www.linkedin.com/posts/activity-7247354293660356609-IT7t&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Where Should I Deploy My K8s Cluster?</title>
      <link>https://vijay.eu/posts/deploy-k8s/</link>
      <pubDate>Sun, 17 May 2020 01:00:19 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/deploy-k8s/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/K8s.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;This week there was an &lt;a href=&#34;https://www.redhat.com/en/blog/red-hat-and-aws-extend-collaboration-introducing-amazon-red-hat-openshift&#34;&gt;announcement&lt;/a&gt; about Amazon Red Hat Openshift. It is an enterprise Kubernetes (K8s) service on AWS jointly managed and supported by AWS and Red Hat. Upon reading more about the service, found out that Red Hat already has two more OpenShift services available on AWS. If you count AWS&amp;rsquo; own managed K8s service Amazon Elastic Kubernetes Service (EKS) then there are four different ways you can run a K8s cluster on top of AWS. I am sure there are many other companies providing similar managed K8s services on top of AWS.&lt;/p&gt;
&lt;p&gt;For a beginner starting to use K8s this is overwhelming. This brings us to the question: &lt;strong&gt;Where should I deploy my K8s cluster?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As always, the answer is: &lt;strong&gt;It Depends&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It depends&lt;/strong&gt; on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your team&amp;rsquo;s K8s expertise&lt;/li&gt;
&lt;li&gt;Your company&amp;rsquo;s budget&lt;/li&gt;
&lt;li&gt;Your data locality requirements&lt;/li&gt;
&lt;li&gt;Your preferred Cloud Vendor&lt;/li&gt;
&lt;li&gt;Your company&amp;rsquo;s already existing deals with Software vendors&lt;/li&gt;
&lt;li&gt;and many more.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You could run your K8s cluster in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On Premises&lt;/li&gt;
&lt;li&gt;Hybrid Cloud&lt;/li&gt;
&lt;li&gt;IaaS&lt;/li&gt;
&lt;li&gt;PaaS&lt;/li&gt;
&lt;li&gt;Others&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;on-premises&#34;&gt;On Premises&lt;/h3&gt;
&lt;p&gt;If you already own datacenters or if you have strict privacy/security requirements for making sure the data does not leave your premises then &lt;em&gt;On Premises&lt;/em&gt; solution is the way to go.&lt;/p&gt;
&lt;p&gt;Install host operating system on the bare metal servers and then install K8s on top of it. Kubeadm is one option. However, be aware that this is a bare bones solution. You have to build/integrate authentication, authorization, dashboard, security, networking plugins, service mesh, storage, the list goes on.&lt;/p&gt;
&lt;p&gt;You could choose to install Openshift or Rancher. These come fully loaded.&lt;/p&gt;
&lt;p&gt;On Premises solutions are usually the slowest ones  to complete the installation as you have to deal  with hardware. It takes time to order, ship, install and configure them.&lt;/p&gt;
&lt;h3 id=&#34;hybrid-cloud&#34;&gt;Hybrid Cloud&lt;/h3&gt;
&lt;p&gt;Amazon Outposts, Google Anthos and Azure Stack provide rack full of servers which you can install in your datacenter. These racks are connected to their Public cloud and you manage it just like VMs on public cloud.&lt;/p&gt;
&lt;p&gt;This option gives you the flexibility of cloud deployment with the advantage of not managing the hardware.&lt;/p&gt;
&lt;p&gt;Keep in mind that this is the most costliest option. Bill can run into millions easily.&lt;/p&gt;
&lt;p&gt;Once you have Outposts, Anthos or Azure Stack rack on premises, you can use their managed K8s solution on top of it. Google Anthos GKE is one such option.&lt;/p&gt;
&lt;p&gt;The timeline depends on the cloud provider and honestly I have no idea about it.&lt;/p&gt;
&lt;h3 id=&#34;iaas&#34;&gt;IaaS&lt;/h3&gt;
&lt;p&gt;If you need full control of the K8s cluster and you are a pro in managing K8s then this is the option to go.&lt;/p&gt;
&lt;p&gt;You install K8s on top of Amazon EC2 or Google Compute Engine or Azure Virtual Machine.&lt;/p&gt;
&lt;p&gt;Several K8s deployment tools like kops, kubespray or KRIB exist. You can also install Red Hat Openshift or Rancher on the virtual machines.&lt;/p&gt;
&lt;p&gt;Use this option only when you have experience running k8s clusters.&lt;/p&gt;
&lt;h3 id=&#34;paas&#34;&gt;PaaS&lt;/h3&gt;
&lt;p&gt;If all you wanted is a K8s cluster and don&amp;rsquo;t know or don&amp;rsquo;t want to know K8s cluster management then this option is for you.&lt;/p&gt;
&lt;p&gt;Managed K8s solutions like Google GKE, Amazon EKS, Amazon Red Hat Openshift, Azure AKS does fit the bill.&lt;/p&gt;
&lt;p&gt;You click a button and you get a cluster and the kubeconfig/credentials to the cluster.&lt;/p&gt;
&lt;p&gt;You might want to customize some options, enable logging, move the API server to private endpoint etc.&lt;/p&gt;
&lt;p&gt;Usually this is a good place to start for development clusters. Deploy the k8s cluster, tune it, test it, run your applications and then customize more.&lt;/p&gt;
&lt;p&gt;Since this is a managed solution, you will not have full control of the cluster. You have to use whatever version they support, don&amp;rsquo;t get access to the API server or etcd servers barring some flags.&lt;/p&gt;
&lt;h3 id=&#34;others&#34;&gt;Others&lt;/h3&gt;
&lt;p&gt;Minikube, kind, k3s are for developments purposes. These software are light weight and are designed to run on your laptop.&lt;/p&gt;
&lt;p&gt;These solutions can be used for learning about k8s, for local testing of your applications.&lt;/p&gt;
&lt;p&gt;K8s distributions like Red Hat Openshift or Rancher can be installed on bare metal, IaaS, and  PaaS. Usually this option is useful if you have more than one type of infrastructure and you want to use the same K8s distribution everywhere. You could build automation on top of it and deploy it any where you want.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this blog post I have tried to cover different ways you can deploy your kubernetes cluster. This list is not exhaustive and I might have missed some options.&lt;/p&gt;
&lt;p&gt;Kubernetes has become the industry standard for running containers and all the major public cloud providers have K8s services.&lt;/p&gt;
&lt;p&gt;Purpose of writing this blog post is to showcase the variety of K8s deployment options you have, be it on a bare metal server, or virtual machine or managed solution like this week&amp;rsquo;s announcement of Amazon Red Hat Openshift.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback by commenting on my tweet below.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Where should I deploy my K8s cluster?&lt;br&gt;My new blog post on this topic.&lt;a href=&#34;https://t.co/sflPzY3Rnt&#34;&gt;https://t.co/sflPzY3Rnt&lt;/a&gt;&lt;br&gt;&lt;br&gt;Do read it and give me feedback.&lt;/p&gt;&amp;mdash; Vijay Kodam (@vijaykodam) &lt;a href=&#34;https://twitter.com/vijaykodam/status/1261783876596350976?ref_src=twsrc%5Etfw&#34;&gt;May 16, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


</description>
    </item>
    
    <item>
      <title>How to login securely to your Amazon EC2 Instance?</title>
      <link>https://vijay.eu/posts/how-to-login-securely-to-amazon-ec2/</link>
      <pubDate>Tue, 12 May 2020 14:42:15 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/how-to-login-securely-to-amazon-ec2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/secure-ec2.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Securing the Amazon EC2 instance is the first thing you have to think while creating it. This post specifically talks about how to secure SSH/RDP port on your EC2 Instances and how not to open port 22/3389 to the Internet (0.0.0.0/0).&lt;/p&gt;
&lt;p&gt;There are several ways to secure your EC2 instances in AWS. Will discuss some of the popular ones.&lt;/p&gt;
&lt;p&gt;When EC2 instance is running in Public subnet, disable password authentication and enable SSH keys based authentication. Secure your SSH port to allow traffic from specific subnet (Ex., 3.2.132.0/24) or your own IP address (Eg., 3.2.132.23/32) by setting security group rules.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;a href=&#34;https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html&#34;&gt;*security group&lt;/a&gt;* acts as a virtual firewall for your instance to control inbound and outbound traffic.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Problem with this method is that whenever your IP address or subnet changes you have to update your security group rules. Managing SSH keys is another task, which can get quite tricky when there are more than few EC2 instances. How to store the SSH keys safely? How to grant or revoke accesses to specific users?&lt;/p&gt;
&lt;p&gt;Another way is to use bastion host, run it in Public subnet and expose it to Internet using security group rules. Create your EC2 instances in a private subnet where there is no access from Internet and no one from outside can access it. Use security group rules to allow SSH traffic into your instance only from the bastion. This way your EC2 instance traffic is secured and only from bastion host you can access your EC2 instance.&lt;/p&gt;
&lt;p&gt;However, the same problem exists as before. How will you secure your SSH/RDP port on the bastion host. You will still have to manage the SSH keys to your bastion host and open inbound ports on the instance.&lt;/p&gt;
&lt;h2 id=&#34;aws-systems-manager-session-manager&#34;&gt;AWS Systems Manager Session Manager&lt;/h2&gt;
&lt;p&gt;Session Manager is part of AWS Systems Manager service. It gives you a browser-based CLI window to access your Windows and Linux EC2 instances without opening inbound SSH/RDP port. No need to create a bastion host. No need to manage SSH keys. Access can be granted or revoked using AWS IAM.&lt;/p&gt;
&lt;p&gt;AWS Systems Manager uses SSM agent running on the EC2 instance to manage the login and other tasks.&lt;/p&gt;
&lt;p&gt;SSM Agent is preinstalled, by default, on the following Amazon Machine Images (AMIs):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Windows Server 2008-2012 R2 AMIs published in November 2016 or later&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Windows Server 2016 and 2019&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Amazon Linux&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Amazon Linux 2&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ubuntu Server 16.04&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ubuntu Server 18.04&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Amazon ECS-Optimized&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You need to create relevant IAM permissions, install or enable SSM agent on the EC2 instances. Once you do it you can either acces your instance from AWS Console or AWS CLI.&lt;/p&gt;
&lt;p&gt;For detailed instructions, refer to &lt;a href=&#34;https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-getting-started.html&#34;&gt;the documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;AWS Systems Manager Sessions Manager lets you manage your entire fleet of EC2 instances, audit the access, grant or revoke access for each instance.&lt;/p&gt;
&lt;h3 id=&#34;notes&#34;&gt;Notes&lt;/h3&gt;
&lt;p&gt;Beware of pressing CTRL-W if you are used to it on the bash shell. It will close your browser window. Change the keyboard shortcuts to update the shortcut.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback or comments on my tweet below:
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;How to login securely to Amazon EC2 without opening SSH port to 0.0.0.0/0.&lt;a href=&#34;https://t.co/iAPvnoawwN&#34;&gt;https://t.co/iAPvnoawwN&lt;/a&gt;&lt;br&gt;&lt;br&gt;This tweet is used for allowing readers to comment on my blogpost. &lt;br&gt;Since it is hosted as static pages using Hugo thought this is a good way to include commenting on my blogpost.&lt;/p&gt;&amp;mdash; Vijay Kodam (@vijaykodam) &lt;a href=&#34;https://twitter.com/vijaykodam/status/1260837110812155904?ref_src=twsrc%5Etfw&#34;&gt;May 14, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ambassador API GW and Keycloak integration</title>
      <link>https://vijay.eu/posts/ambassador-keycloak-integration/</link>
      <pubDate>Sun, 23 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vijay.eu/posts/ambassador-keycloak-integration/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/cloud.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.getambassador.io/&#34;&gt;Ambassador API GW&lt;/a&gt; is an open source, Kubernetes-Native microservices API Gateway built on the Envoy Proxy.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.keycloak.org/&#34;&gt;Keycloak&lt;/a&gt; is an open source identity and access management solution. Keycloak supports OpenID Connect, SAML, OAuth2 and LDAP.&lt;/p&gt;
&lt;p&gt;Ambassador supports authenticating incoming requests. When configured, Ambassador will check with a third party authentication service prior to routing an incoming request. An AuthService manifest configures Ambassador to use an external service to check authentication and authorization for incoming requests. Each incoming request is authenticated before routing to its destination.&lt;/p&gt;
&lt;p&gt;In this blog we will be using Keycloak as our IAM solution and integrating it with Ambassador API GW. After integrating Keycloak with Ambassador, incoming API requests will be redirected to Keycloak login page for authentication before allowing access to those APIs.&lt;/p&gt;
&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Ambassador API GW is deployed and listening for API requests. Follow the &lt;a href=&#34;https://www.getambassador.io/user-guide/getting-started&#34;&gt;official instructions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;httpbin example application is configured for the URL: &lt;code&gt;http://&amp;lt;Ambassador URL&amp;gt;/httpbin&lt;/code&gt;
You can follow the instructions mentioned &lt;a href=&#34;https://www.getambassador.io/user-guide/getting-started/#3-creating-your-first-route&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Make sure &lt;code&gt;http://&amp;lt;Ambassador URL&amp;gt;/httpbin&lt;/code&gt; is routed through Ambassador API GW and it should open &lt;code&gt;httpbin.org&lt;/code&gt; website.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In some of the commands below, you need to substitute relevant IP or URL for Keycloak and Ambassador. You will find them in this notation: &lt;code&gt;&amp;lt;Ambassador IP-or-URL&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;Your-Keycloak-IP-or-URL&amp;gt;&lt;/code&gt;.       Similarly there are other variables in &lt;code&gt;&amp;lt; &amp;gt;&lt;/code&gt; which you need to substitute before running those commands.&lt;/p&gt;
&lt;h2 id=&#34;set-up-keycloak&#34;&gt;Set up Keycloak&lt;/h2&gt;
&lt;p&gt;Use your existing keycloak setup if you already have. If not you can start one quicky using below instructions.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Please note that below keycloak setup is not secure and is used only for testing the Ambassador-Keycloak integration. Do not use this in production. Use it at your own risk.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For testing purposes docker version of keycloak will be used for this demo.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;docker run -e KEYCLOAK_USER=&amp;lt;add-your-keycloak-user&amp;gt; \
            -e KEYCLOAK_PASSWORD=&amp;lt;keycloak-password&amp;gt; \
                                  -p 0.0.0.0:80:8080 \
                                -itd --name keycloak \
                                      jboss/keycloak
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Above command will start keycloak on your Linux machine. It will set admin username, password and binds keycloak to port 80. This setup uses keycloak&amp;rsquo;s default H2 DB, which should not be used in production. Note your IP address.&lt;/p&gt;
&lt;p&gt;Login to Keycloak by visiting &lt;code&gt;http://&amp;lt;your-ip&amp;gt;&lt;/code&gt; in your browser. Use the username and password supplied in the docker run command to login to Keycloak.&lt;/p&gt;
&lt;p&gt;Use the existing &amp;ldquo;master&amp;rdquo; realm. Create a client and a user for our testing purposes.
Click on &lt;code&gt;Clients -&amp;gt; Create&lt;/code&gt;. Create button is on the right side of the page.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture6.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Add &lt;code&gt;Client ID&lt;/code&gt; as &lt;code&gt;test&lt;/code&gt;. Select &amp;ldquo;&lt;code&gt;Client Protocol&lt;/code&gt;&amp;rdquo; as &amp;ldquo;openid-connect&amp;rdquo;. You can leave other fields empty. Click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture1.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;After saving, a new window will open with more details. Turn On &lt;code&gt;Authorization Enabled&lt;/code&gt; option. It will automatically turn On &lt;code&gt;Service Accounts Enabled&lt;/code&gt; option. Leave it like that.&lt;/p&gt;
&lt;p&gt;Fill &lt;code&gt;Valid Redirect URIs&lt;/code&gt; with &lt;code&gt;http://&amp;lt;Ambassador URL&amp;gt;/*&lt;/code&gt;. Click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture2.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture8.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;On the same page, go to &lt;code&gt;Credentials&lt;/code&gt; tab as shown below. Note the secret which is needed when creating &amp;ldquo;ambassador-auth-client-secret&amp;rdquo; in the next section. Use it wherever &lt;code&gt;&amp;lt;YOUR_OIDC_CLIENT_SECRET&amp;gt;&lt;/code&gt; is mentioned.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture4.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Click Users section on the keycloak page, to create users. Add username, email and select email verified. Click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture9.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the same page, go to Credentials tab.  Set the new password, and turn Temporary to Off.&lt;br&gt;
Click Reset Password.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture10.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;When dialog window opens click Change Password.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture11.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Please note that this is done only for testing ambassador-keycloak integration. 
Please do not do this in production or in any setup. Follow these instructions at your own risk.&lt;/p&gt;
&lt;p&gt;Now go back and click Users section in Keycloak. In the Users page, click &amp;ldquo;View all Users&amp;rdquo; and you should see the newly created user.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture12.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;setup-oidc-auth-integration-with-keycloak&#34;&gt;Setup OIDC Auth integration with Keycloak&lt;/h2&gt;
&lt;p&gt;Thanks to Antti Myyra for developing Ambassador-Auth-OIDC, which will be used to integrate Keycloak with Ambassador API GW.&lt;/p&gt;
&lt;p&gt;Run below commands to clone ambassador-auth-oidc. Below you can choose to run it either in docker or in k8s. Don&amp;rsquo;t run both.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;git clone https://github.com/ajmyyra/ambassador-auth-oidc.git
cd ambassador-auth-oidc/
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;running-ambassador-auth-in-docker&#34;&gt;Running ambassador auth In Docker&lt;/h3&gt;
&lt;p&gt;Use these instructions if your Ambassador API gateway is running as docker container and not in k8s.&lt;/p&gt;
&lt;p&gt;Above setup is running keycloak as docker container and listening on port 80. Below ambassador-auth-oidc docker container will listen on port 8080.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;docker run -p 0.0.0.0:8080:8080 \
      -e OIDC_PROVIDER=&amp;#34;http://&amp;lt;Your-Keycloak-IP-or-URL&amp;gt;/auth/realms/master&amp;#34; \
      -e SELF_URL=&amp;#34;http://&amp;lt;Ambassador IP-or-URL&amp;gt;:8080&amp;#34; \
      -e OIDC_SCOPES=&amp;#34;profile email&amp;#34; \
      -e CLIENT_ID=&amp;#34;test&amp;#34; \
      -e CLIENT_SECRET=&amp;#34;&amp;lt;YOUR_OIDC_CLIENT_SECRET&amp;gt;&amp;#34; \
      ajmyyra/ambassador-auth-oidc:1.3
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;running-ambassador-auth-in-kubernetes&#34;&gt;Running Ambassador Auth in Kubernetes&lt;/h3&gt;
&lt;p&gt;Use this setup if you are already running Ambassador API GW in K8s.
Make sure Ambassador API GW is up and running before creating secrets.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl create secret generic ambassador-auth-jwt-key --from-literal=jwt-key=$(openssl rand -base64 64|tr -d &amp;#39;\n &amp;#39;)
kubectl create secret generic ambassador-auth-redis-password --from-literal=redis-password=$(openssl rand -base64 20)
kubectl create secret generic ambassador-auth-oidc-provider --from-literal=oidc-provider=&amp;#34;http://&amp;lt;Your-Keycloak-IP-or-URL&amp;gt;/auth/realms/master&amp;#34;
kubectl create secret generic ambassador-auth-self-url --from-literal=self-url=&amp;#34;http://&amp;lt;Ambassador IP-or-URL&amp;gt;&amp;#34;
kubectl create secret generic ambassador-auth-client-id --from-literal=client-id=&amp;#34;test&amp;#34;
kubectl create secret generic ambassador-auth-client-secret --from-literal=client-secret=&amp;lt;YOUR_OIDC_CLIENT_SECRET&amp;gt;
kubectl get secrets # To confirm they&amp;#39;ve been created
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Run below commands in the root directory of ambassador-auth-oidc. This will start the ambassador-auth-oidc container on K8s.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;cd ambassador-auth-oidc/
cp misc/auth-deployment.yaml.example auth-deployment.yaml
cp misc/auth-service.yaml.example auth-service.yaml

kubectl create -f auth-deployment.yaml
kubectl create -f auth-service.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Make sure ambassador-auth-oidc is up and running. Also check the logs to make sure everything is alright.&lt;/p&gt;
&lt;p&gt;Now go to &lt;code&gt;http://&amp;lt;Ambassador IP-or-URL&amp;gt;/httpbin&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It should automatically redirect you to Keycloak page for logging in.
Enter your &amp;ldquo;test&amp;rdquo; user credentials. After successful login it should automatically redirect you to &lt;code&gt;http://&amp;lt;Ambassador IP-or-URL&amp;gt;/httpbin&lt;/code&gt; page.&lt;/p&gt;
&lt;p&gt;We have successfully integrated Keycloak with Ambassador API GW and tested API Authentication.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
