<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS on Vijay Kodam</title>
    <link>https://vijay.eu/categories/aws/</link>
    <description>Recent content in AWS on Vijay Kodam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 15 Feb 2025 00:22:33 +0200</lastBuildDate>
    
	<atom:link href="https://vijay.eu/categories/aws/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Hands-on Bedrock Agents workshop</title>
      <link>https://vijay.eu/posts/bedrock-agents-workshop/</link>
      <pubDate>Sat, 15 Feb 2025 00:22:33 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/bedrock-agents-workshop/</guid>
      <description>&lt;p&gt;Are agents the missing piece for LLMs to super-charge real-world adoption? Today, I had the opportunity to attend AWS Immersion Day at AWS Helsinki office and try hands-on workshop on Agents, RAG, and more.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/bedrock-ws-1.jpeg&#34; alt=&#34;bedrock-workshop&#34;&gt;&lt;/p&gt;
&lt;p&gt;Thanks Amazon Web Services (AWS), Ankit Nigam, Kimmo Isosomppi, Heidi T√§htinen, Ezaldeen Arafat for organizing this workshop. This was immensely useful and improved my understanding of Agents, RAG, Guardrails and inference.&lt;/p&gt;
&lt;p&gt;As part of the hands-on workshop, I have created a mortage-processing-agent which uses RAG to add domain specific knowledge base and then created agents which can determine if end-user can afford it based on their financial situation.
After that, created Amazon Bedrock Flows that orchestrates entire workflow. Last but not the least, created Guardrails to implement safeguards and enforce responsible AI policies for my GenAI application.&lt;/p&gt;
&lt;p&gt;Here is the mortgage processing agent I built during the hands-on workshop.
The highlighted yellow box is the prompt user enters followed by the response from Bedrock.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/bedrock-ws-handson.jpeg&#34; alt=&#34;bedrock-handson&#34;&gt;&lt;/p&gt;
&lt;p&gt;All in all, this was a very good way to get hands-on experience on Amazon Bedrock Agents, RAG, Flows and Guardrails.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/bedrock-ws-agents.jpeg&#34; alt=&#34;bedrock-agents&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Presented on EKS Auto Mode at the AWS Helsinki Meetup</title>
      <link>https://vijay.eu/posts/presented-at-aws-meetup/</link>
      <pubDate>Thu, 06 Feb 2025 20:17:49 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/presented-at-aws-meetup/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/aws-meetup-1.png&#34; alt=&#34;AWS Meetup Presenting&#34;&gt;&lt;/p&gt;
&lt;p&gt;Had an amazing time presenting at the AWS meetup today! It was great to share my insights on how EKS Auto mode can help the customers get rid off undifferentiated heavy lifting.&lt;/p&gt;
&lt;p&gt;Started with the basics of Kubernetes for those new to it and then went on to explain how EKS helps customers and how EKS Auto mode will simplify K8s Day 2 operations. The lively Q&amp;amp;A was a highlight, and I learned a lot from the audience&amp;rsquo;s perspectives.  Public speaking is a journey, and I&amp;rsquo;m grateful for the opportunity to practice and grow.&lt;/p&gt;
&lt;p&gt;A huge thank you to Petri Rosenstr√∂m, Rolf Koski and Accenture for organizing the Amazon Web Services (AWS) meetup today in Helsinki.&lt;/p&gt;
&lt;p&gt;Also learnt about Accenture&amp;rsquo;s technology vision from Juha Takala, Emil Nyback and interesting GenAI talk from Niklas Liljestrand !!! All great talks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/aws-meetup-2.png&#34; alt=&#34;AWS Meetup Presenting 2&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>This new EventBridge capability simplifies your cross-account deployments</title>
      <link>https://vijay.eu/posts/eventbridge-new-capability/</link>
      <pubDate>Wed, 22 Jan 2025 12:12:42 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/eventbridge-new-capability/</guid>
      <description>&lt;p&gt;This new capability in &lt;strong&gt;EventBridge&lt;/strong&gt; is going to simplify your cross-account &lt;strong&gt;Event Driven Architecture&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;AWS introduced cross account targets for EventBridge event buses today. Now you can add &lt;strong&gt;SQS&lt;/strong&gt;, &lt;strong&gt;Lambda&lt;/strong&gt; or &lt;strong&gt;SNS&lt;/strong&gt; as targets from a different account. Previously only EventBridge in another account could be added.&lt;/p&gt;
&lt;p&gt;The architecture diagram from the AWS blog is attached in this post. It perfectly captures everything you need to know about this feature.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/eventbridge1.jpg&#34; alt=&#34;AWS Event Bridge&#34;&gt;&lt;/p&gt;
&lt;p&gt;Remember to do these two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add relevant execution &amp;ldquo;role&amp;rdquo; in source AWS account EventBridge rule.&lt;/li&gt;
&lt;li&gt;Apply &amp;ldquo;resource policy&amp;rdquo; to SQS/SNS/Lambda in the Target Account.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;Role&amp;rdquo;&lt;/strong&gt; for Source Account and &lt;strong&gt;&amp;ldquo;Resource policy&amp;rdquo;&lt;/strong&gt; for Target account. Everything else is same as before.&lt;/p&gt;
&lt;p&gt;This makes sure security is taken care from both Source and Target AWS accounts and avoids any abuse or DDoS situations.&lt;/p&gt;
&lt;p&gt;Read the AWS Blog &lt;a href=&#34;https://aws.amazon.com/blogs/compute/introducing-cross-account-targets-for-amazon-eventbridge-event-buses/&#34;&gt;post here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Surprising side effect of running EKS Auto Mode</title>
      <link>https://vijay.eu/posts/surprising-side-effect-eks-auto/</link>
      <pubDate>Tue, 21 Jan 2025 12:10:31 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/surprising-side-effect-eks-auto/</guid>
      <description>&lt;p&gt;One surprising side effect you will notice when you move to EKS Auto mode is that you cannot create a Classic Load Balancer (CLB) using Kubernetes Service annotations. You can only create Network Load Balancers (NLB) using K8s Service annotations.&lt;/p&gt;
&lt;p&gt;This restriction came into place due to the automatic inclusion of AWS Load Balancer controller as an add-on in EKS Auto mode. AFAIK, there is no way to disable or remove that add-on from EKS Auto mode cluster.&lt;/p&gt;
&lt;p&gt;If you are utilizing other ingress controllers like HAProxy, then you cannot create a CLB (HTTPS) using Service annotations. You can only create NLBs using Service annotations and route the traffic through HAProxy ingress controller. After that you can create ingresses which can utilize HAProxy as ingress controller.&lt;/p&gt;
&lt;p&gt;This means that if you have been using HAProxy ingress controller or other similar ingress controllers then this limitation restricts you to service HTTP/HTTPS traffic through them.&lt;/p&gt;
&lt;p&gt;Since this is a new release, I haven&amp;rsquo;t seen any update in their docs. I am curious on how other ingress controllers handle this change.&lt;/p&gt;
&lt;p&gt;Have you faced this issue in EKS Auto mode? Did you manage to fix it? I would like to know your thoughts on this?&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;. You can find all my previous blog posts in &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Have you seen multi-session support enabled in your AWS Console?</title>
      <link>https://vijay.eu/posts/multi-sessions-in-aws-console/</link>
      <pubDate>Thu, 16 Jan 2025 11:47:06 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/multi-sessions-in-aws-console/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/multisess.png&#34; alt=&#34;multisession&#34;&gt;
Image: Image shows the multi-session support enabled in my AWS Console.&lt;/p&gt;
&lt;p&gt;Observed it today morning that multi-session support is enabled in my AWS account.&lt;/p&gt;
&lt;p&gt;This feature saves lot of effort and time for me. I work with different AWS accounts and logging into those AWS consoles or switching between them is an extra step. Usually I use different browsers to keep both AWS console logins active but it increases CPU/memory load on my PC.&lt;/p&gt;
&lt;p&gt;Now I can use single browser and login to two different accounts simultaneously. Saves CPU/RAM in my PC as I don&amp;rsquo;t have to run two browsers now.&lt;/p&gt;
&lt;p&gt;AWS manages this by adding unique account specific URLs to identify which account you are in even though you access the same EC2 or EKS service in both accounts.&lt;/p&gt;
&lt;p&gt;This is a big feature for me from usability perspective. Currently this is being rolled out and is available only for limited number of user accounts.&lt;/p&gt;
&lt;p&gt;Watch out for this feature in your AWS account and give it a try!!!&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Do you run your database on Kubernetes?</title>
      <link>https://vijay.eu/posts/database-on-kubernetes/</link>
      <pubDate>Fri, 10 Jan 2025 11:34:54 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/database-on-kubernetes/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/dbink8s.webp&#34; alt=&#34;dbink8s&#34;&gt;&lt;/p&gt;
&lt;p&gt;Do you run your database on Kubernetes? This has been an evergreen debate. Where does it stand now?&lt;/p&gt;
&lt;p&gt;Kubernetes has come a long way from running only stateless workloads early on to now supporting statefulsets with improvements in sticky identity, persistent storage and unique network identity. Kubernetes has democratized the container orchestration and given the world tools to run most software at scale. This is only one part of the solution.&lt;/p&gt;
&lt;p&gt;Databases built to run directly on servers or virtual machines have different features to make them highly available, resilient and scalable. Now if you bring those databases and run them on Kubernetes then it is a recipe for disaster. In the recent years, there have been cloud native databases built to run on Kubernetes. This is the remaining part of the solution.&lt;/p&gt;
&lt;p&gt;You have a container orchestrator platform like Kubernetes which runs most of your software and now with cloud-native databases, you can run them on Kubernetes too.&lt;/p&gt;
&lt;p&gt;Best of both worlds? What about latency? How do you handle frequent k8s release upgrades every three months? Now with EKS Auto mode, the worker nodes max lifetime is just 21 days. Imagine moving around your database nodes every two-three weeks? Is it recommended in production? Do you instead use managed database service from hashtag#AWS hashtag#GoogleCloud or hashtag#Azure?&lt;/p&gt;
&lt;p&gt;There is no right or wrong answer and &amp;ldquo;It Depends&amp;rdquo; on the software architecture and business constraints.&lt;/p&gt;
&lt;p&gt;I would like to hear from you all. Write your opinion in the comments below. Do you run your database on Kubernetes? Why? Why not? What are your reasons? Are you using it in production? What is the adoption for such databases?&lt;/p&gt;
&lt;p&gt;If you are new to my posts, I regularly post about AWS, EKS, Kubernetes and Cloud computing related topics. Do follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and visit &lt;a href=&#34;https://dev.to/vijaykodam&#34;&gt;my dev.to posts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Image generated using DALL.E to depict storage in the cloud.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What is ARC Zonal shift feature in EKS?</title>
      <link>https://vijay.eu/posts/eks-arc-zonal-shift/</link>
      <pubDate>Mon, 30 Dec 2024 01:04:17 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/eks-arc-zonal-shift/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/snowdrop.png&#34; alt=&#34;snowdrop&#34;&gt;
&lt;em&gt;Image Credits:&lt;/em&gt; Generated using DALL.E. &lt;em&gt;This image depicts &lt;strong&gt;resiliency&lt;/strong&gt; in nature similar to what is expected from your AWS architecture :)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Recently I have created an EKS Auto mode cluster and observed that &lt;strong&gt;‚ÄúARC Zonal shift‚Äù&lt;/strong&gt; feature was enabled for my EKS cluster.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Amazon Application Recovery Controller (ARC)&lt;/strong&gt; helps simplify and automate recovery for highly available applications. It was initially known as ‚ÄúRoute 53 ARC‚Äù and since then has expanded to support Amazon EC2 Auto scaling groups, ALB, NLB and now EKS. So it is now just Amazon ARC.&lt;/p&gt;
&lt;p&gt;You can recover from an impaired Availability Zone (AZ) using ARC Zonal Shift and Zonal autoshift. Zonal shift is used when you manually trigger it to shift traffic away from an impaired AZ. Use Zonal autoshift to let AWS monitor and shift traffic on your behalf.&lt;/p&gt;
&lt;p&gt;If you want to run resilient and highly available applications across multi-AZs in EKS and you want to survive an AZ going down then this is the feature (EKS Zonal Shift) you need.&lt;/p&gt;
&lt;p&gt;Remember that this will only redirect internal east-west traffic inside your EKS traffic between your pods. If you want to redirect traffic from loadbalancers similarly then you have to enable an ALB or NLB with ARC Zonal shift.&lt;/p&gt;
&lt;p&gt;Performing a zonal shift enables you to achieve rapid recovery from application failures in a single Availability Zone (AZ). This is helpful to build resilience in case of an AZ impairment or when an AZ is down.&lt;/p&gt;
&lt;p&gt;You can enable it from EKS cluster creation step or enable it afterwards for already running clusters. If you are creating EKS auto mode cluster with ‚ÄúQuick configuration‚Äù option then ARC Zonal shift is enabled by default.&lt;/p&gt;
&lt;p&gt;With zonal shift, you can temporarily mitigate issues and incidents by triggering a shift and redirecting in-cluster network traffic to a healthy AZ.&lt;/p&gt;
&lt;p&gt;For this to work, you should already be running EKS worker nodes in multiple AZs (at least three) for HA and resiliency and your applications are already running in multiple AZs. So if your application is already running in three different AZs and if one AZ is impaired then Zonal shift will redirect traffic away from impaired AZ to healthy AZs. In this case, you will have your application running in two AZs as highly available after the third one went down.&lt;/p&gt;
&lt;p&gt;Ideally such setup comes with cost so use it for highly critical workloads where you need such level of high-availability and resiliency.&lt;/p&gt;
&lt;p&gt;Check the EKS Zonal shift documentation to learn more: &lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/zone-shift.html&#34;&gt;https://docs.aws.amazon.com/eks/latest/userguide/zone-shift.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Follow me on LinkedIn for more content related to Kubernetes, EKS and AWS in general. Visit my website at &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;https://vijay.eu/posts&lt;/a&gt; for all my posts in one place.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Do you know that EKS Auto Mode enforces a 21-day maximum node lifetime?</title>
      <link>https://vijay.eu/posts/eks-auto-max-node-lifetime/</link>
      <pubDate>Thu, 12 Dec 2024 14:13:02 +0530</pubDate>
      
      <guid>https://vijay.eu/posts/eks-auto-max-node-lifetime/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/EKS-Auto-Mode.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;Do you know that EKS Auto Mode enforces a 21-day maximum node lifetime?&lt;/p&gt;
&lt;p&gt;EKS Auto mode cluster manages worker nodes on your behalf.
Karpenter deletes worker nodes in EKS auto mode nodepools after 21 days of node lifetime. This is the maximum node lifetime. It will be replaced with a new node.&lt;/p&gt;
&lt;p&gt;This is needed for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;providing security patches&lt;/li&gt;
&lt;li&gt;OS updates&lt;/li&gt;
&lt;li&gt;component upgrades&lt;/li&gt;
&lt;li&gt;improves security posture&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-if-you-want-to-modify-the-maximum-node-lifetime&#34;&gt;What if you want to modify the maximum node lifetime?&lt;/h2&gt;
&lt;p&gt;You can reduce the maximum node lifetime by creating a custom NodePool with ‚Äúspec.template.spec.expireAfter‚Äù with a value of node lifetime in hours. Max is 21 days.&lt;/p&gt;
&lt;h2 id=&#34;how-to-disable-it&#34;&gt;How to disable it?&lt;/h2&gt;
&lt;p&gt;If for some reason, you do not want to delete worker nodes so frequent or if you want to keep the nodes static then you can create a new Managed Node Group and add nodes in it.
You can create both EKS Auto mode nodepools and Managed Node groups (without auto mode) in the same EKS cluster. These are called mixed-mode clusters.
I will be covering more about mixed-mode clusters in future posts.&lt;/p&gt;
&lt;p&gt;For more insights on EKS, AWS, Kubernetes, and Cloud Architecture, follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; and check out &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt; for all my blog posts in one place.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>First Impressions of EKS Auto Mode ‚Äì A Game Changer!</title>
      <link>https://vijay.eu/posts/eks-auto-first-impressions/</link>
      <pubDate>Wed, 04 Dec 2024 23:13:15 +0530</pubDate>
      
      <guid>https://vijay.eu/posts/eks-auto-first-impressions/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/aws-eks-pic.png&#34; alt=&#34;Kubernetes&#34;&gt;
&lt;em&gt;Image Credit: From AWS EKS Blog&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Here are my thoughts after initial few days of using &lt;strong&gt;EKS Auto mode&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;AWS has truly raised the bar with EKS Auto Mode, a new feature announced at &lt;strong&gt;re:Invent 2024&lt;/strong&gt;. This innovation automates much of the undifferentiated heavy lifting, allowing customers to focus on what matters most: building great applications.&lt;/p&gt;
&lt;h2 id=&#34;my-hands-on-experience&#34;&gt;My Hands-On Experience&lt;/h2&gt;
&lt;p&gt;I set up an EKS Auto Mode cluster from scratch and was pleasantly surprised by how much AWS now handles post-installation. You can read in &lt;a href=&#34;https://www.linkedin.com/pulse/how-create-eks-auto-mode-cluster-vijay-kumar-kodam-oqw4f/&#34;&gt;more detail about it here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let me break down what &lt;em&gt;Day 2 operations&lt;/em&gt; typically involve:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Managed Node Groups&lt;/strong&gt;: Create managed node groups and wait for worker nodes to come up.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;EKS Node capabilities&lt;/strong&gt;: Most of them were running as Kubernetes Daemonsets on worker nodes before. Now they run as system processes managed by AWS. This includes components such as service discovery, service load balancing, pod networking, block storage, and credential vending.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add-Ons Installation&lt;/strong&gt;: Select and install versions for multiple EKS add-ons (latest, standard, or older). Like coredns, EBS CSI driver, CNI driver, EKS pod identity etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Load Balancer Controller&lt;/strong&gt;: Install the AWS Load Balancer Controller for ingress traffic handling.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cost Optimization&lt;/strong&gt;: Install Karpenter to manage pod bin-packing, scale nodes dynamically, and select cost-efficient EC2 instances.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OS Security patching&lt;/strong&gt;: Address OS security vulnerabilities identified by AWS Security Hub.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cluster Upgrades&lt;/strong&gt;: Over time, you need to upgrade Kubernetes control plane versions and meticulously plan worker node updates. This is a continuous process every 3-6 months.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, imagine all these tasks being automated by AWS. That‚Äôs EKS Auto Mode for you!&lt;/p&gt;
&lt;h2 id=&#34;key-highlights-from-my-testing&#34;&gt;Key Highlights from My Testing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;No Idle Nodes&lt;/strong&gt;: When I launched my first EKS Auto Mode cluster, there were no worker nodes running initially‚Äîjust built-in &amp;ldquo;general-purpose&amp;rdquo; and &amp;ldquo;system&amp;rdquo; node pools.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dynamic Scaling&lt;/strong&gt;: After deploying my first application, Karpenter automatically spun up a worker node tailored to the app&amp;rsquo;s resource requirements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cost Efficiency&lt;/strong&gt;: Upon deleting the application, Karpenter scaled down the node, saving money by avoiding idle resources.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This level of automation simplifies cluster operations and significantly reduces costs.&lt;/p&gt;
&lt;h2 id=&#34;pricing-update&#34;&gt;Pricing Update&lt;/h2&gt;
&lt;p&gt;EKS Auto Mode introduces a pay-as-you-go control plane pricing model based on the number of EC2 worker nodes, a shift from the flat fee for the standard EKS control plane. While it‚Äôs a slight increase in cost, the time and effort saved make it a Win-Win for both AWS and customers. Find more about &lt;a href=&#34;https://aws.amazon.com/eks/pricing/&#34;&gt;EKS Auto mode pricing here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What‚Äôs Next?&lt;/h2&gt;
&lt;p&gt;I‚Äôve &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7269311743338663936/&#34;&gt;created a demo video&lt;/a&gt; showcasing EKS Auto Mode in action. If you‚Äôre curious, I highly recommend giving this feature a try!&lt;/p&gt;
&lt;p&gt;For more insights on EKS, AWS, Kubernetes, and Cloud Architecture, follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; or check out my blog at &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;https://vijay.eu/posts&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let me know your thoughts on this exciting new feature! üëá&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to secure microservices architecture in AWS?</title>
      <link>https://vijay.eu/posts/aws-secure-microservices/</link>
      <pubDate>Mon, 04 Nov 2024 00:06:59 +0200</pubDate>
      
      <guid>https://vijay.eu/posts/aws-secure-microservices/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/ms-secure.png&#34; alt=&#34;aws-security&#34;&gt;
&lt;strong&gt;Image Credits:&lt;/strong&gt; Microservices architecture image made by me using draw.io&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Security in Public Cloud is utmost important. Losing access to your website or attackers deleting your database are catastrophic-company-ending-events.&lt;/p&gt;
&lt;h3 id=&#34;shared-responsibility-model&#34;&gt;Shared Responsibility Model&lt;/h3&gt;
&lt;p&gt;Security and Compliance is a shared responsibility between AWS and the customer.&lt;/p&gt;
&lt;p&gt;Here is the definition from AWS documentation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;AWS is responsible for the &lt;strong&gt;&amp;ldquo;Security of the Cloud&amp;rdquo;&lt;/strong&gt;. AWS is responsible for protecting the infrastructure that runs all of the services offered in the AWS Cloud. This infrastructure is composed of the hardware, software, networking, and facilities that run AWS Cloud services.&lt;/p&gt;
&lt;p&gt;Customer is responsible for the &lt;strong&gt;‚ÄúSecurity in the Cloud‚Äù&lt;/strong&gt;. Customer responsibility will be determined by the AWS Cloud services that a customer selects. This determines the amount of configuration work the customer must perform as part of their security responsibilities.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Refer AWS Documentation for more information on Shared Responsibility Model.&lt;/p&gt;
&lt;h3 id=&#34;best-practices&#34;&gt;Best Practices&lt;/h3&gt;
&lt;p&gt;Luckily, AWS provides you with a host of security services to improve your security posture from Day One. Note that this is not an exhaustive list and &amp;ldquo;it depends&amp;rdquo; on where you run and what services you use. Here are some of the steps to secure your microservices architecture in AWS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use AWS Shield for DDoS protection&lt;/li&gt;
&lt;li&gt;Use AWS GuardDuty for intelligent threat detection.&lt;/li&gt;
&lt;li&gt;Use AWS IAM for managing identities and access to AWS resources&lt;/li&gt;
&lt;li&gt;Use AWS WAF to protect your web applications from common exploits.&lt;/li&gt;
&lt;li&gt;Use AWS Certificates Manager for encrypting website data in transit using TLS/SSL certificates.&lt;/li&gt;
&lt;li&gt;Use AWS KMS keys to encrypt all EBS volumes and Aurora DB (data at rest)&lt;/li&gt;
&lt;li&gt;Use AWS Secrets Manager to store your application secrets.&lt;/li&gt;
&lt;li&gt;Run all your workloads in private subnets. Allow only needed traffic using Security Groups and NACLs.&lt;/li&gt;
&lt;li&gt;If your applications need Internet connectivity to download updates then configure NAT GW in public subnet.&lt;/li&gt;
&lt;li&gt;You could also use VPC peering to isolate specific workloads in a different VPC in a different AWS account.&lt;/li&gt;
&lt;li&gt;Use Amazon Inspector to scan EC2 for security vulnerabilities&lt;/li&gt;
&lt;li&gt;Use Amazon Security Hub to automate AWS security checks and centralize security alerts.&lt;/li&gt;
&lt;li&gt;Use AWS Cognito for authentication and authorization of the API requests.&lt;/li&gt;
&lt;li&gt;Use CloudTrail for audit logging.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Security should not be an after thought when building and running applications in AWS. Utilize some or all of these AWS security services to make your microservices architecture secure.&lt;/p&gt;
&lt;p&gt;What have I missed? This post assumed microservices are running in EC2 VMs. If microservices are running in Amazon EKS then it calls for a totally new approach and very long post. I will post about EKS security soon.&lt;/p&gt;
&lt;p&gt;Follow me on LinkedIn at &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;https://www.linkedin.com/in/vijaykodam/&lt;/a&gt; where I post articles about AWS, Kubernetes and cloud computing in general. I also post all my articles to my blog at &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;https://vijay.eu/posts&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unlock Up to 40% AWS Cost Savings with Graviton!</title>
      <link>https://vijay.eu/posts/save-costs-with-graviton/</link>
      <pubDate>Sun, 27 Oct 2024 00:14:32 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/save-costs-with-graviton/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/graviton.png&#34; alt=&#34;Graviton&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Image Credits: From AWS Blog&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There are multiple ways to cost optimize your applications running in AWS. One effective way to achieve this is by using &lt;strong&gt;Graviton-based instance types&lt;/strong&gt;. Graviton processor-based instances are gaining popularity as more applications and AWS services now support them.&lt;/p&gt;
&lt;p&gt;Amazon EC2 instances powered by AWS Graviton2 processors provide up to &lt;strong&gt;40% better price performance&lt;/strong&gt; compared to fifth-generation x86-based instances for a wide variety of workloads.&lt;/p&gt;
&lt;h3 id=&#34;climate-friendly-computing-with-graviton&#34;&gt;Climate-Friendly Computing with Graviton&lt;/h3&gt;
&lt;p&gt;Using Graviton also has climate benefits: it reduces your carbon footprint by using up to &lt;strong&gt;60% less energy&lt;/strong&gt; than comparable EC2 instances for the same performance.&lt;/p&gt;
&lt;p&gt;By choosing Graviton-based instances over traditional x86 instances, you can unlock significant savings. Since Apple adopted ARM processors for their MacBooks, ARM has gained widespread support across operating systems and applications, ensuring seamless compatibility. AWS‚Äôs push for Graviton has further motivated the software industry to embrace ARM-based processors.&lt;/p&gt;
&lt;p&gt;AWS has been steadily expanding Graviton support across its services, making it easier than ever to leverage cost savings with ARM-based processors.&lt;/p&gt;
&lt;h3 id=&#34;graviton-support-across-aws-managed-services&#34;&gt;Graviton Support Across AWS Managed Services&lt;/h3&gt;
&lt;p&gt;Here are some of the popular AWS managed services that support Graviton:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Amazon EKS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amazon ECS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amazon Aurora&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amazon RDS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AWS Lambda&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amazon OpenSearch Service&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For AWS managed services where Graviton-based instances are supported, like EKS, you can create Graviton-based instances for the worker nodes. Refer to this &lt;a href=&#34;https://github.com/aws/aws-graviton-getting-started/blob/main/managed_services.md&#34;&gt;link&lt;/a&gt; for a full list of supported AWS services.&lt;/p&gt;
&lt;h3 id=&#34;graviton-support-in-kubernetes-and-the-container-ecosystem&#34;&gt;Graviton Support in Kubernetes and the Container Ecosystem&lt;/h3&gt;
&lt;p&gt;Kubernetes and containers have become the de facto platform for running microservices today. Graviton is supported by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Amazon EKS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Containerd&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Helm&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Grafana&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prometheus&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loki&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Istio&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ArgoCD&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Terraform&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;‚Ä¶and many other tools. Here is the &lt;a href=&#34;https://github.com/aws/aws-graviton-getting-started/blob/main/containers.md#ecosystem-support&#34;&gt;full list of popular software&lt;/a&gt; within the container ecosystem that explicitly supports arm64/Graviton.&lt;/p&gt;
&lt;p&gt;Additionally, &lt;strong&gt;.NET 9&lt;/strong&gt; and many older versions support Graviton.&lt;/p&gt;
&lt;h3 id=&#34;operating-systems-supporting-graviton&#34;&gt;Operating Systems Supporting Graviton&lt;/h3&gt;
&lt;p&gt;Several major operating systems also support Graviton, including &lt;strong&gt;Amazon Linux 2023&lt;/strong&gt;, &lt;strong&gt;Ubuntu&lt;/strong&gt;, &lt;strong&gt;RHEL&lt;/strong&gt;, &lt;strong&gt;SUSE&lt;/strong&gt;, &lt;strong&gt;Alpine Linux&lt;/strong&gt;, and more.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;try-amazon-ec2-t4g-instances-for-free-today&#34;&gt;Try Amazon EC2 T4g Instances for Free Today&lt;/h3&gt;
&lt;p&gt;Amazon EC2 T4g instances are the next generation of general-purpose burstable instances powered by Arm-based AWS Graviton2 processors. Try Amazon EC2 &lt;code&gt;t4g.small&lt;/code&gt; instances powered by AWS Graviton2 processors free for up to &lt;strong&gt;750 hours per month until Dec 31st, 2024&lt;/strong&gt;. Refer to the &lt;a href=&#34;https://aws.amazon.com/ec2/faqs/&#34;&gt;Amazon EC2 FAQ&lt;/a&gt; for additional details.&lt;/p&gt;
&lt;p&gt;With this &lt;a href=&#34;https://aws.amazon.com/ec2/graviton/getting-started/&#34;&gt;step-by-step guide from AWS&lt;/a&gt;, you can adopt Graviton-based instances for your workloads.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Consider including Graviton-based instances in your workload, whether in your Kubernetes clusters, EC2 instances, Lambda functions, or databases.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Save money and save the planet.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Graviton is one of several ways to optimize costs in AWS. I will cover more cost optimization strategies in future posts, so follow me to learn more about AWS, cost optimization, and Kubernetes. I also post all my articles on &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fastest and Cheapest Ways to Delete Millions of Files from Amazon S3</title>
      <link>https://vijay.eu/posts/s3-delete-millions-of-files/</link>
      <pubDate>Mon, 14 Oct 2024 00:42:32 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/s3-delete-millions-of-files/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Managing data in &lt;strong&gt;Amazon S3&lt;/strong&gt; can be a daunting task, especially when you&amp;rsquo;re faced with the need to delete millions of objects. Whether you‚Äôre dealing with old backups, temporary files, or simply restructuring your data, choosing the right method to delete these files is crucial. The right approach can save you time and money, ensuring that you maintain an efficient cloud environment.&lt;/p&gt;
&lt;p&gt;In this post, we‚Äôll explore various methods to delete files from an S3 bucket, highlighting the &lt;strong&gt;fastest&lt;/strong&gt; and &lt;strong&gt;cheapest&lt;/strong&gt; options available.&lt;/p&gt;
&lt;h2 id=&#34;different-ways-to-delete-files-from-s3&#34;&gt;Different Ways to Delete Files from S3&lt;/h2&gt;
&lt;h3 id=&#34;1-aws-management-console&#34;&gt;1. AWS Management Console&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;AWS Management Console&lt;/strong&gt; allows you to manually delete files through a user-friendly interface. While this method is straightforward and suitable for small batches, it becomes impractical for large datasets.&lt;/p&gt;
&lt;h3 id=&#34;2-aws-cli&#34;&gt;2. AWS CLI&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;AWS Command Line Interface (CLI)&lt;/strong&gt; is a popular choice for users who prefer script-based operations. You can use the following command to delete files recursively:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;aws s3 rm s3://bucket-name --recursive
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;However, it‚Äôs important to note that the AWS CLI is primarily &lt;strong&gt;single-threaded&lt;/strong&gt;, which can lead to slower performance when deleting large numbers of objects.&lt;/p&gt;
&lt;h3 id=&#34;3-s3cmd&#34;&gt;3. s3cmd&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;s3cmd&lt;/strong&gt; is another command-line tool that offers more features than the AWS CLI. It allows for some level of parallelism, making it &lt;strong&gt;slightly faster&lt;/strong&gt; than the AWS CLI. The command for recursive deletion is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;s3cmd del s3://bucket-name --recursive
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;While it provides a better performance boost, it still doesn‚Äôt match the speed of more advanced tools.&lt;/p&gt;
&lt;h3 id=&#34;4-s3-batch-operations&#34;&gt;4. S3 Batch Operations&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;S3 Batch Operations&lt;/strong&gt; are designed for large-scale tasks and can delete billions of objects. However, this method incurs additional costs based on the number of objects processed, which may not be ideal for budget-conscious users.&lt;/p&gt;
&lt;h3 id=&#34;5-s3-lifecycle-policies&#34;&gt;5. S3 Lifecycle Policies&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;S3 Lifecycle Policies&lt;/strong&gt; are an excellent way to automate the deletion of files without incurring extra costs. You can set rules to automatically delete objects after a specified duration or based on specific conditions. However, deletions may take &lt;strong&gt;up to 24 hours&lt;/strong&gt; to execute.&lt;/p&gt;
&lt;h3 id=&#34;6-s5cmd&#34;&gt;6. s5cmd&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;s5cmd&lt;/strong&gt; is a newer, highly parallelized tool that excels in speed. It can delete thousands of files per second and is particularly useful for massive deletions. To delete files using s5cmd, you can use the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;s5cmd rm s3://bucket-name/*
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;comparing-methods-fastest-vs-cheapest&#34;&gt;Comparing Methods: Fastest vs. Cheapest&lt;/h2&gt;
&lt;h3 id=&#34;fastest-method-s5cmd&#34;&gt;Fastest Method: s5cmd&lt;/h3&gt;
&lt;p&gt;When it comes to speed, &lt;strong&gt;s5cmd&lt;/strong&gt; is the clear winner. It is designed for high-performance operations and leverages &lt;strong&gt;multi-threading&lt;/strong&gt; and &lt;strong&gt;batch processing&lt;/strong&gt; to maximize efficiency. With &lt;strong&gt;s5cmd&lt;/strong&gt;, you can expect deletion rates to be up to &lt;strong&gt;100x faster&lt;/strong&gt; than the AWS CLI, making it an excellent choice for scenarios where time is critical.&lt;/p&gt;
&lt;h3 id=&#34;cheapest-method-s3-lifecycle-policies&#34;&gt;Cheapest Method: S3 Lifecycle Policies&lt;/h3&gt;
&lt;p&gt;If minimizing costs is your primary concern, &lt;strong&gt;S3 Lifecycle Policies&lt;/strong&gt; are the way to go. This method allows you to automate deletions without incurring additional charges. You can set lifecycle rules that trigger deletions based on file age or other criteria, making it ideal for long-term data management. While it may take longer to process (up to 24 hours), it eliminates the need for any new costs, making it perfect for &lt;strong&gt;cost-conscious&lt;/strong&gt; environments.&lt;/p&gt;
&lt;h2 id=&#34;why-these-methods-are-the-best&#34;&gt;Why These Methods Are the Best&lt;/h2&gt;
&lt;h3 id=&#34;speed-considerations&#34;&gt;Speed Considerations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;For Speed&lt;/strong&gt;: When you need to delete millions of objects quickly, &lt;strong&gt;s5cmd&lt;/strong&gt; stands out due to its ability to handle multiple requests simultaneously. This is particularly advantageous in environments where data is frequently updated or removed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cost-considerations&#34;&gt;Cost Considerations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;For Cost&lt;/strong&gt;: &lt;strong&gt;S3 Lifecycle Policies&lt;/strong&gt; allow you to automate data management tasks without incurring any additional charges. This is crucial for businesses looking to optimize their cloud costs while maintaining a clean and organized data structure.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Choosing the right method to delete millions of files from an S3 bucket depends on your specific use case. If speed is your priority, &lt;strong&gt;s5cmd&lt;/strong&gt; is the best tool for the job. Conversely, if you‚Äôre focused on minimizing costs, &lt;strong&gt;S3 Lifecycle Policies&lt;/strong&gt; offer an automated, no-cost solution for managing your data over time.&lt;/p&gt;
&lt;p&gt;By understanding these options, you can make informed decisions that streamline your data management processes in AWS S3, saving both time and money in the long run.&lt;/p&gt;
&lt;p&gt;Follow me on LinkedIn at &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;https://www.linkedin.com/in/vijaykodam/&lt;/a&gt;  where I post articles about AWS, Kubernetes and cloud computing in general.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Save Hours During Amazon EKS Upgrades with This One Simple Step!</title>
      <link>https://vijay.eu/posts/eks-upgrade-insights/</link>
      <pubDate>Thu, 03 Oct 2024 01:00:19 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/eks-upgrade-insights/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/K8s.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;üöÄ Save Hours During Amazon EKS Upgrades with This One Simple Step! üöÄ&lt;/p&gt;
&lt;p&gt;If you‚Äôve ever managed EKS clusters in production, you know how crucial it is to keep them updated to leverage the latest features and maintain security.&lt;/p&gt;
&lt;p&gt;üîÑ But before starting an upgrade, have you checked the &amp;ldquo;Upgrade Insights&amp;rdquo; tab on the EKS cluster page?&lt;/p&gt;
&lt;p&gt;Previously, our team had to manually check for deprecations and potential issues before every upgrade, spending hours in the process. Now, with the &amp;ldquo;Upgrade Insights&amp;rdquo; feature, EKS continuously monitors audit logs, detects deprecation errors, and updates the insights daily.&lt;/p&gt;
&lt;p&gt;This small step has transformed our process and saved us countless hours of debugging and maintenance. üí°&lt;/p&gt;
&lt;p&gt;‚úÖ &lt;strong&gt;Pro tip&lt;/strong&gt;: Always review the &amp;ldquo;Upgrade Insights&amp;rdquo; tab before upgrading your clusters to ensure a smooth transition to newer Kubernetes versions.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback by commenting on my LinkedIn post below.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/posts/activity-7247354293660356609-IT7t&#34;&gt;https://www.linkedin.com/posts/activity-7247354293660356609-IT7t&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Where Should I Deploy My K8s Cluster?</title>
      <link>https://vijay.eu/posts/deploy-k8s/</link>
      <pubDate>Sun, 17 May 2020 01:00:19 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/deploy-k8s/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/K8s.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;This week there was an &lt;a href=&#34;https://www.redhat.com/en/blog/red-hat-and-aws-extend-collaboration-introducing-amazon-red-hat-openshift&#34;&gt;announcement&lt;/a&gt; about Amazon Red Hat Openshift. It is an enterprise Kubernetes (K8s) service on AWS jointly managed and supported by AWS and Red Hat. Upon reading more about the service, found out that Red Hat already has two more OpenShift services available on AWS. If you count AWS&amp;rsquo; own managed K8s service Amazon Elastic Kubernetes Service (EKS) then there are four different ways you can run a K8s cluster on top of AWS. I am sure there are many other companies providing similar managed K8s services on top of AWS.&lt;/p&gt;
&lt;p&gt;For a beginner starting to use K8s this is overwhelming. This brings us to the question: &lt;strong&gt;Where should I deploy my K8s cluster?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As always, the answer is: &lt;strong&gt;It Depends&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It depends&lt;/strong&gt; on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your team&amp;rsquo;s K8s expertise&lt;/li&gt;
&lt;li&gt;Your company&amp;rsquo;s budget&lt;/li&gt;
&lt;li&gt;Your data locality requirements&lt;/li&gt;
&lt;li&gt;Your preferred Cloud Vendor&lt;/li&gt;
&lt;li&gt;Your company&amp;rsquo;s already existing deals with Software vendors&lt;/li&gt;
&lt;li&gt;and many more.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You could run your K8s cluster in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On Premises&lt;/li&gt;
&lt;li&gt;Hybrid Cloud&lt;/li&gt;
&lt;li&gt;IaaS&lt;/li&gt;
&lt;li&gt;PaaS&lt;/li&gt;
&lt;li&gt;Others&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;on-premises&#34;&gt;On Premises&lt;/h3&gt;
&lt;p&gt;If you already own datacenters or if you have strict privacy/security requirements for making sure the data does not leave your premises then &lt;em&gt;On Premises&lt;/em&gt; solution is the way to go.&lt;/p&gt;
&lt;p&gt;Install host operating system on the bare metal servers and then install K8s on top of it. Kubeadm is one option. However, be aware that this is a bare bones solution. You have to build/integrate authentication, authorization, dashboard, security, networking plugins, service mesh, storage, the list goes on.&lt;/p&gt;
&lt;p&gt;You could choose to install Openshift or Rancher. These come fully loaded.&lt;/p&gt;
&lt;p&gt;On Premises solutions are usually the slowest ones  to complete the installation as you have to deal  with hardware. It takes time to order, ship, install and configure them.&lt;/p&gt;
&lt;h3 id=&#34;hybrid-cloud&#34;&gt;Hybrid Cloud&lt;/h3&gt;
&lt;p&gt;Amazon Outposts, Google Anthos and Azure Stack provide rack full of servers which you can install in your datacenter. These racks are connected to their Public cloud and you manage it just like VMs on public cloud.&lt;/p&gt;
&lt;p&gt;This option gives you the flexibility of cloud deployment with the advantage of not managing the hardware.&lt;/p&gt;
&lt;p&gt;Keep in mind that this is the most costliest option. Bill can run into millions easily.&lt;/p&gt;
&lt;p&gt;Once you have Outposts, Anthos or Azure Stack rack on premises, you can use their managed K8s solution on top of it. Google Anthos GKE is one such option.&lt;/p&gt;
&lt;p&gt;The timeline depends on the cloud provider and honestly I have no idea about it.&lt;/p&gt;
&lt;h3 id=&#34;iaas&#34;&gt;IaaS&lt;/h3&gt;
&lt;p&gt;If you need full control of the K8s cluster and you are a pro in managing K8s then this is the option to go.&lt;/p&gt;
&lt;p&gt;You install K8s on top of Amazon EC2 or Google Compute Engine or Azure Virtual Machine.&lt;/p&gt;
&lt;p&gt;Several K8s deployment tools like kops, kubespray or KRIB exist. You can also install Red Hat Openshift or Rancher on the virtual machines.&lt;/p&gt;
&lt;p&gt;Use this option only when you have experience running k8s clusters.&lt;/p&gt;
&lt;h3 id=&#34;paas&#34;&gt;PaaS&lt;/h3&gt;
&lt;p&gt;If all you wanted is a K8s cluster and don&amp;rsquo;t know or don&amp;rsquo;t want to know K8s cluster management then this option is for you.&lt;/p&gt;
&lt;p&gt;Managed K8s solutions like Google GKE, Amazon EKS, Amazon Red Hat Openshift, Azure AKS does fit the bill.&lt;/p&gt;
&lt;p&gt;You click a button and you get a cluster and the kubeconfig/credentials to the cluster.&lt;/p&gt;
&lt;p&gt;You might want to customize some options, enable logging, move the API server to private endpoint etc.&lt;/p&gt;
&lt;p&gt;Usually this is a good place to start for development clusters. Deploy the k8s cluster, tune it, test it, run your applications and then customize more.&lt;/p&gt;
&lt;p&gt;Since this is a managed solution, you will not have full control of the cluster. You have to use whatever version they support, don&amp;rsquo;t get access to the API server or etcd servers barring some flags.&lt;/p&gt;
&lt;h3 id=&#34;others&#34;&gt;Others&lt;/h3&gt;
&lt;p&gt;Minikube, kind, k3s are for developments purposes. These software are light weight and are designed to run on your laptop.&lt;/p&gt;
&lt;p&gt;These solutions can be used for learning about k8s, for local testing of your applications.&lt;/p&gt;
&lt;p&gt;K8s distributions like Red Hat Openshift or Rancher can be installed on bare metal, IaaS, and  PaaS. Usually this option is useful if you have more than one type of infrastructure and you want to use the same K8s distribution everywhere. You could build automation on top of it and deploy it any where you want.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this blog post I have tried to cover different ways you can deploy your kubernetes cluster. This list is not exhaustive and I might have missed some options.&lt;/p&gt;
&lt;p&gt;Kubernetes has become the industry standard for running containers and all the major public cloud providers have K8s services.&lt;/p&gt;
&lt;p&gt;Purpose of writing this blog post is to showcase the variety of K8s deployment options you have, be it on a bare metal server, or virtual machine or managed solution like this week&amp;rsquo;s announcement of Amazon Red Hat Openshift.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback by commenting on my tweet below.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Where should I deploy my K8s cluster?&lt;br&gt;My new blog post on this topic.&lt;a href=&#34;https://t.co/sflPzY3Rnt&#34;&gt;https://t.co/sflPzY3Rnt&lt;/a&gt;&lt;br&gt;&lt;br&gt;Do read it and give me feedback.&lt;/p&gt;&amp;mdash; Vijay Kodam (@vijaykodam) &lt;a href=&#34;https://twitter.com/vijaykodam/status/1261783876596350976?ref_src=twsrc%5Etfw&#34;&gt;May 16, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


</description>
    </item>
    
  </channel>
</rss>
