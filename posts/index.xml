<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Vijay Kodam</title>
    <link>https://vijay.eu/posts/</link>
    <description>Recent content in Posts on Vijay Kodam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 09 Dec 2024 23:13:15 +0530</lastBuildDate>
    
	<atom:link href="https://vijay.eu/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>First Impressions of EKS Auto Mode ‚Äì A Game Changer!</title>
      <link>https://vijay.eu/posts/eks-auto-first-impressions/</link>
      <pubDate>Mon, 09 Dec 2024 23:13:15 +0530</pubDate>
      
      <guid>https://vijay.eu/posts/eks-auto-first-impressions/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/aws-eks-pic.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here are my thoughts after initial few days of using &lt;strong&gt;EKS Auto mode&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;AWS has truly raised the bar with EKS Auto Mode, a new feature announced at &lt;strong&gt;re:Invent 2024&lt;/strong&gt;. This innovation automates much of the undifferentiated heavy lifting, allowing customers to focus on what matters most: building great applications.&lt;/p&gt;
&lt;h2 id=&#34;-my-hands-on-experience&#34;&gt;üõ† My Hands-On Experience&lt;/h2&gt;
&lt;p&gt;I set up an EKS Auto Mode cluster from scratch and was pleasantly surprised by how much AWS now handles post-installation. You can read in &lt;a href=&#34;https://www.linkedin.com/pulse/how-create-eks-auto-mode-cluster-vijay-kumar-kodam-oqw4f/&#34;&gt;more detail about it here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let me break down what &lt;em&gt;Day 2 operations&lt;/em&gt; typically involve:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Managed Node Groups: Create managed node groups and wait for worker nodes to come up.&lt;/li&gt;
&lt;li&gt;EKS Node capabilities: Most of them were running as Kubernetes Daemonsets on worker nodes before. Now they run as system processes managed by AWS. This includes components such as service discovery, service load balancing, pod networking, block storage, and credential vending.&lt;/li&gt;
&lt;li&gt;Add-Ons Installation: Select and install versions for multiple EKS add-ons (latest, standard, or older). Like coredns, EBS CSI driver, CNI driver, EKS pod identity etc.&lt;/li&gt;
&lt;li&gt;Load Balancer Controller: Install the AWS Load Balancer Controller for ingress traffic handling.&lt;/li&gt;
&lt;li&gt;Cost Optimization: Install Karpenter to manage pod bin-packing, scale nodes dynamically, and select cost-efficient EC2 instances.&lt;/li&gt;
&lt;li&gt;OS Security patching: Address OS security vulnerabilities identified by AWS Security Hub.&lt;/li&gt;
&lt;li&gt;Cluster Upgrades: Over time, you need to upgrade Kubernetes control plane versions and meticulously plan worker node updates. This is a continuous process every 3-6 months.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, imagine all these tasks being automated by AWS. That‚Äôs EKS Auto Mode for you!&lt;/p&gt;
&lt;h2 id=&#34;-key-highlights-from-my-testing&#34;&gt;üí° Key Highlights from My Testing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;No Idle Nodes: When I launched my first EKS Auto Mode cluster, there were no worker nodes running initially‚Äîjust built-in &amp;ldquo;general-purpose&amp;rdquo; and &amp;ldquo;system&amp;rdquo; node pools.&lt;/li&gt;
&lt;li&gt;Dynamic Scaling: After deploying my first application, Karpenter automatically spun up a worker node tailored to the app&amp;rsquo;s resource requirements.&lt;/li&gt;
&lt;li&gt;Cost Efficiency: Upon deleting the application, Karpenter scaled down the node, saving money by avoiding idle resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This level of automation simplifies cluster operations and significantly reduces costs.&lt;/p&gt;
&lt;h2 id=&#34;-pricing-update&#34;&gt;üîç Pricing Update&lt;/h2&gt;
&lt;p&gt;EKS Auto Mode introduces a pay-as-you-go control plane pricing model based on the number of EC2 worker nodes, a shift from the flat fee for the standard EKS control plane. While it‚Äôs a slight increase in cost, the time and effort saved make it a Win-Win for both AWS and customers. Find more about &lt;a href=&#34;https://aws.amazon.com/eks/pricing/&#34;&gt;EKS Auto mode pricing here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;-whats-next&#34;&gt;üé• What‚Äôs Next?&lt;/h2&gt;
&lt;p&gt;I‚Äôve &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:7269311743338663936/&#34;&gt;created a demo video&lt;/a&gt; showcasing EKS Auto Mode in action. If you‚Äôre curious, I highly recommend giving this feature a try!&lt;/p&gt;
&lt;p&gt;For more insights on EKS, AWS, Kubernetes, and Cloud Architecture, follow me in &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;LinkedIn&lt;/a&gt; or check out my blog at &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;https://vijay.eu/posts&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let me know your thoughts on this exciting new feature! üëá&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unlock Up to 40% AWS Cost Savings with Graviton!</title>
      <link>https://vijay.eu/posts/save-costs-with-graviton/</link>
      <pubDate>Sun, 27 Oct 2024 00:14:32 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/save-costs-with-graviton/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/graviton.png&#34; alt=&#34;Graviton&#34;&gt;&lt;/p&gt;
&lt;p&gt;There are multiple ways to cost optimize your applications running in AWS. One effective way to achieve this is by using &lt;strong&gt;Graviton-based instance types&lt;/strong&gt;. Graviton processor-based instances are gaining popularity as more applications and AWS services now support them.&lt;/p&gt;
&lt;p&gt;Amazon EC2 instances powered by AWS Graviton2 processors provide up to &lt;strong&gt;40% better price performance&lt;/strong&gt; compared to fifth-generation x86-based instances for a wide variety of workloads.&lt;/p&gt;
&lt;h3 id=&#34;climate-friendly-computing-with-graviton&#34;&gt;Climate-Friendly Computing with Graviton&lt;/h3&gt;
&lt;p&gt;Using Graviton also has climate benefits: it reduces your carbon footprint by using up to &lt;strong&gt;60% less energy&lt;/strong&gt; than comparable EC2 instances for the same performance.&lt;/p&gt;
&lt;p&gt;By choosing Graviton-based instances over traditional x86 instances, you can unlock significant savings. Since Apple adopted ARM processors for their MacBooks, ARM has gained widespread support across operating systems and applications, ensuring seamless compatibility. AWS‚Äôs push for Graviton has further motivated the software industry to embrace ARM-based processors.&lt;/p&gt;
&lt;p&gt;AWS has been steadily expanding Graviton support across its services, making it easier than ever to leverage cost savings with ARM-based processors.&lt;/p&gt;
&lt;h3 id=&#34;graviton-support-across-aws-managed-services&#34;&gt;Graviton Support Across AWS Managed Services&lt;/h3&gt;
&lt;p&gt;Here are some of the popular AWS managed services that support Graviton:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Amazon EKS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amazon ECS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amazon Aurora&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amazon RDS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AWS Lambda&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amazon OpenSearch Service&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For AWS managed services where Graviton-based instances are supported, like EKS, you can create Graviton-based instances for the worker nodes. Refer to this &lt;a href=&#34;https://github.com/aws/aws-graviton-getting-started/blob/main/managed_services.md&#34;&gt;link&lt;/a&gt; for a full list of supported AWS services.&lt;/p&gt;
&lt;h3 id=&#34;graviton-support-in-kubernetes-and-the-container-ecosystem&#34;&gt;Graviton Support in Kubernetes and the Container Ecosystem&lt;/h3&gt;
&lt;p&gt;Kubernetes and containers have become the de facto platform for running microservices today. Graviton is supported by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Amazon EKS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Containerd&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Helm&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Grafana&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prometheus&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loki&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Istio&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ArgoCD&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Terraform&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;‚Ä¶and many other tools. Here is the &lt;a href=&#34;https://github.com/aws/aws-graviton-getting-started/blob/main/containers.md#ecosystem-support&#34;&gt;full list of popular software&lt;/a&gt; within the container ecosystem that explicitly supports arm64/Graviton.&lt;/p&gt;
&lt;p&gt;Additionally, &lt;strong&gt;.NET 9&lt;/strong&gt; and many older versions support Graviton.&lt;/p&gt;
&lt;h3 id=&#34;operating-systems-supporting-graviton&#34;&gt;Operating Systems Supporting Graviton&lt;/h3&gt;
&lt;p&gt;Several major operating systems also support Graviton, including &lt;strong&gt;Amazon Linux 2023&lt;/strong&gt;, &lt;strong&gt;Ubuntu&lt;/strong&gt;, &lt;strong&gt;RHEL&lt;/strong&gt;, &lt;strong&gt;SUSE&lt;/strong&gt;, &lt;strong&gt;Alpine Linux&lt;/strong&gt;, and more.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;try-amazon-ec2-t4g-instances-for-free-today&#34;&gt;Try Amazon EC2 T4g Instances for Free Today&lt;/h3&gt;
&lt;p&gt;Amazon EC2 T4g instances are the next generation of general-purpose burstable instances powered by Arm-based AWS Graviton2 processors. Try Amazon EC2 &lt;code&gt;t4g.small&lt;/code&gt; instances powered by AWS Graviton2 processors free for up to &lt;strong&gt;750 hours per month until Dec 31st, 2024&lt;/strong&gt;. Refer to the &lt;a href=&#34;https://aws.amazon.com/ec2/faqs/&#34;&gt;Amazon EC2 FAQ&lt;/a&gt; for additional details.&lt;/p&gt;
&lt;p&gt;With this &lt;a href=&#34;https://aws.amazon.com/ec2/graviton/getting-started/&#34;&gt;step-by-step guide from AWS&lt;/a&gt;, you can adopt Graviton-based instances for your workloads.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Consider including Graviton-based instances in your workload, whether in your Kubernetes clusters, EC2 instances, Lambda functions, or databases.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Save money and save the planet.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Graviton is one of several ways to optimize costs in AWS. I will cover more cost optimization strategies in future posts, so follow me to learn more about AWS, cost optimization, and Kubernetes. I also post all my articles on &lt;a href=&#34;https://vijay.eu/posts&#34;&gt;my blog&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fastest and Cheapest Ways to Delete Millions of Files from Amazon S3</title>
      <link>https://vijay.eu/posts/s3-delete-millions-of-files/</link>
      <pubDate>Mon, 14 Oct 2024 00:42:32 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/s3-delete-millions-of-files/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Managing data in &lt;strong&gt;Amazon S3&lt;/strong&gt; can be a daunting task, especially when you&amp;rsquo;re faced with the need to delete millions of objects. Whether you‚Äôre dealing with old backups, temporary files, or simply restructuring your data, choosing the right method to delete these files is crucial. The right approach can save you time and money, ensuring that you maintain an efficient cloud environment.&lt;/p&gt;
&lt;p&gt;In this post, we‚Äôll explore various methods to delete files from an S3 bucket, highlighting the &lt;strong&gt;fastest&lt;/strong&gt; and &lt;strong&gt;cheapest&lt;/strong&gt; options available.&lt;/p&gt;
&lt;h2 id=&#34;different-ways-to-delete-files-from-s3&#34;&gt;Different Ways to Delete Files from S3&lt;/h2&gt;
&lt;h3 id=&#34;1-aws-management-console&#34;&gt;1. AWS Management Console&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;AWS Management Console&lt;/strong&gt; allows you to manually delete files through a user-friendly interface. While this method is straightforward and suitable for small batches, it becomes impractical for large datasets.&lt;/p&gt;
&lt;h3 id=&#34;2-aws-cli&#34;&gt;2. AWS CLI&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;AWS Command Line Interface (CLI)&lt;/strong&gt; is a popular choice for users who prefer script-based operations. You can use the following command to delete files recursively:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;aws s3 rm s3://bucket-name --recursive
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;However, it‚Äôs important to note that the AWS CLI is primarily &lt;strong&gt;single-threaded&lt;/strong&gt;, which can lead to slower performance when deleting large numbers of objects.&lt;/p&gt;
&lt;h3 id=&#34;3-s3cmd&#34;&gt;3. s3cmd&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;s3cmd&lt;/strong&gt; is another command-line tool that offers more features than the AWS CLI. It allows for some level of parallelism, making it &lt;strong&gt;slightly faster&lt;/strong&gt; than the AWS CLI. The command for recursive deletion is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;s3cmd del s3://bucket-name --recursive
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;While it provides a better performance boost, it still doesn‚Äôt match the speed of more advanced tools.&lt;/p&gt;
&lt;h3 id=&#34;4-s3-batch-operations&#34;&gt;4. S3 Batch Operations&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;S3 Batch Operations&lt;/strong&gt; are designed for large-scale tasks and can delete billions of objects. However, this method incurs additional costs based on the number of objects processed, which may not be ideal for budget-conscious users.&lt;/p&gt;
&lt;h3 id=&#34;5-s3-lifecycle-policies&#34;&gt;5. S3 Lifecycle Policies&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;S3 Lifecycle Policies&lt;/strong&gt; are an excellent way to automate the deletion of files without incurring extra costs. You can set rules to automatically delete objects after a specified duration or based on specific conditions. However, deletions may take &lt;strong&gt;up to 24 hours&lt;/strong&gt; to execute.&lt;/p&gt;
&lt;h3 id=&#34;6-s5cmd&#34;&gt;6. s5cmd&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;s5cmd&lt;/strong&gt; is a newer, highly parallelized tool that excels in speed. It can delete thousands of files per second and is particularly useful for massive deletions. To delete files using s5cmd, you can use the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;s5cmd rm s3://bucket-name/*
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;comparing-methods-fastest-vs-cheapest&#34;&gt;Comparing Methods: Fastest vs. Cheapest&lt;/h2&gt;
&lt;h3 id=&#34;fastest-method-s5cmd&#34;&gt;Fastest Method: s5cmd&lt;/h3&gt;
&lt;p&gt;When it comes to speed, &lt;strong&gt;s5cmd&lt;/strong&gt; is the clear winner. It is designed for high-performance operations and leverages &lt;strong&gt;multi-threading&lt;/strong&gt; and &lt;strong&gt;batch processing&lt;/strong&gt; to maximize efficiency. With &lt;strong&gt;s5cmd&lt;/strong&gt;, you can expect deletion rates to be up to &lt;strong&gt;100x faster&lt;/strong&gt; than the AWS CLI, making it an excellent choice for scenarios where time is critical.&lt;/p&gt;
&lt;h3 id=&#34;cheapest-method-s3-lifecycle-policies&#34;&gt;Cheapest Method: S3 Lifecycle Policies&lt;/h3&gt;
&lt;p&gt;If minimizing costs is your primary concern, &lt;strong&gt;S3 Lifecycle Policies&lt;/strong&gt; are the way to go. This method allows you to automate deletions without incurring additional charges. You can set lifecycle rules that trigger deletions based on file age or other criteria, making it ideal for long-term data management. While it may take longer to process (up to 24 hours), it eliminates the need for any new costs, making it perfect for &lt;strong&gt;cost-conscious&lt;/strong&gt; environments.&lt;/p&gt;
&lt;h2 id=&#34;why-these-methods-are-the-best&#34;&gt;Why These Methods Are the Best&lt;/h2&gt;
&lt;h3 id=&#34;speed-considerations&#34;&gt;Speed Considerations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;For Speed&lt;/strong&gt;: When you need to delete millions of objects quickly, &lt;strong&gt;s5cmd&lt;/strong&gt; stands out due to its ability to handle multiple requests simultaneously. This is particularly advantageous in environments where data is frequently updated or removed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cost-considerations&#34;&gt;Cost Considerations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;For Cost&lt;/strong&gt;: &lt;strong&gt;S3 Lifecycle Policies&lt;/strong&gt; allow you to automate data management tasks without incurring any additional charges. This is crucial for businesses looking to optimize their cloud costs while maintaining a clean and organized data structure.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Choosing the right method to delete millions of files from an S3 bucket depends on your specific use case. If speed is your priority, &lt;strong&gt;s5cmd&lt;/strong&gt; is the best tool for the job. Conversely, if you‚Äôre focused on minimizing costs, &lt;strong&gt;S3 Lifecycle Policies&lt;/strong&gt; offer an automated, no-cost solution for managing your data over time.&lt;/p&gt;
&lt;p&gt;By understanding these options, you can make informed decisions that streamline your data management processes in AWS S3, saving both time and money in the long run.&lt;/p&gt;
&lt;p&gt;Follow me on LinkedIn at &lt;a href=&#34;https://www.linkedin.com/in/vijaykodam/&#34;&gt;https://www.linkedin.com/in/vijaykodam/&lt;/a&gt;  where I post articles about AWS, Kubernetes and cloud computing in general.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Save Hours During Amazon EKS Upgrades with This One Simple Step!</title>
      <link>https://vijay.eu/posts/eks-upgrade-insights/</link>
      <pubDate>Thu, 03 Oct 2024 01:00:19 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/eks-upgrade-insights/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/K8s.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;üöÄ Save Hours During Amazon EKS Upgrades with This One Simple Step! üöÄ&lt;/p&gt;
&lt;p&gt;If you‚Äôve ever managed EKS clusters in production, you know how crucial it is to keep them updated to leverage the latest features and maintain security.&lt;/p&gt;
&lt;p&gt;üîÑ But before starting an upgrade, have you checked the &amp;ldquo;Upgrade Insights&amp;rdquo; tab on the EKS cluster page?&lt;/p&gt;
&lt;p&gt;Previously, our team had to manually check for deprecations and potential issues before every upgrade, spending hours in the process. Now, with the &amp;ldquo;Upgrade Insights&amp;rdquo; feature, EKS continuously monitors audit logs, detects deprecation errors, and updates the insights daily.&lt;/p&gt;
&lt;p&gt;This small step has transformed our process and saved us countless hours of debugging and maintenance. üí°&lt;/p&gt;
&lt;p&gt;‚úÖ &lt;strong&gt;Pro tip&lt;/strong&gt;: Always review the &amp;ldquo;Upgrade Insights&amp;rdquo; tab before upgrading your clusters to ensure a smooth transition to newer Kubernetes versions.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback by commenting on my LinkedIn post below.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/posts/activity-7247354293660356609-IT7t&#34;&gt;https://www.linkedin.com/posts/activity-7247354293660356609-IT7t&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kubernetes 10th Birthday</title>
      <link>https://vijay.eu/posts/kubernetes-10th-birthday/</link>
      <pubDate>Thu, 06 Jun 2024 06:06:36 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/kubernetes-10th-birthday/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/k8s10.jpg&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Celebrating 10 Years of Kubernetes!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m thrilled to be part of the incredible Kubernetes journey that started 10 years ago!&lt;/p&gt;
&lt;p&gt;Back in the early days, I was deep in the world of containers. Then came the chance to build Nokia&amp;rsquo;s Digital Automation Cloud and we chose Kubernetes as the foundation. Those were wild times ‚Äì Kubernetes didn&amp;rsquo;t even had ingress yet, so we had to get creative to manage incoming traffic!&lt;/p&gt;
&lt;p&gt;One of the biggest challenges we faced was managing the explosion of containers. Every company was moving workloads from VMs to containers, but there was no good way to orchestrate them. Several solutions emerged, like Docker Swarm, Mesos, and Red Hat&amp;rsquo;s Openshift (pre-Kubernetes).&lt;/p&gt;
&lt;p&gt;However, Kubernetes, with its Apache v2 license and Google&amp;rsquo;s Borg experience backing it, gained the most traction. It offered a powerful, open-source platform that could handle complex container deployments.&lt;/p&gt;
&lt;p&gt;Gradually, Kubernetes became the gold standard for container orchestration. Openshift, a visionary platform, even adopted Kubernetes as its engine early on, adding features like &amp;ldquo;routes&amp;rdquo; and multi-tenancy that Kubernetes later incorporated as Ingress and RBAC. This collaborative spirit, with everyone contributing back to the core project, is what truly fueled Kubernetes&amp;rsquo; success.&lt;/p&gt;
&lt;p&gt;Today, cloud providers like AWS (EKS) and Microsoft (AKS) offer managed Kubernetes services, making it easier than ever to deploy and manage containerized applications.&lt;/p&gt;
&lt;p&gt;The impact of Kubernetes is undeniable. Now, when companies build software, Kubernetes is the de-facto standard platform, regardless of cloud provider. It&amp;rsquo;s become the expected foundation for modern application development.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s to many more years of innovation with Kubernetes!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;#kubernetes #containerorchestration #cloudnative #devops #opensource&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Where Should I Deploy My K8s Cluster?</title>
      <link>https://vijay.eu/posts/deploy-k8s/</link>
      <pubDate>Sun, 17 May 2020 01:00:19 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/deploy-k8s/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/K8s.png&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;p&gt;This week there was an &lt;a href=&#34;https://www.redhat.com/en/blog/red-hat-and-aws-extend-collaboration-introducing-amazon-red-hat-openshift&#34;&gt;announcement&lt;/a&gt; about Amazon Red Hat Openshift. It is an enterprise Kubernetes (K8s) service on AWS jointly managed and supported by AWS and Red Hat. Upon reading more about the service, found out that Red Hat already has two more OpenShift services available on AWS. If you count AWS&amp;rsquo; own managed K8s service Amazon Elastic Kubernetes Service (EKS) then there are four different ways you can run a K8s cluster on top of AWS. I am sure there are many other companies providing similar managed K8s services on top of AWS.&lt;/p&gt;
&lt;p&gt;For a beginner starting to use K8s this is overwhelming. This brings us to the question: &lt;strong&gt;Where should I deploy my K8s cluster?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As always, the answer is: &lt;strong&gt;It Depends&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It depends&lt;/strong&gt; on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your team&amp;rsquo;s K8s expertise&lt;/li&gt;
&lt;li&gt;Your company&amp;rsquo;s budget&lt;/li&gt;
&lt;li&gt;Your data locality requirements&lt;/li&gt;
&lt;li&gt;Your preferred Cloud Vendor&lt;/li&gt;
&lt;li&gt;Your company&amp;rsquo;s already existing deals with Software vendors&lt;/li&gt;
&lt;li&gt;and many more.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You could run your K8s cluster in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On Premises&lt;/li&gt;
&lt;li&gt;Hybrid Cloud&lt;/li&gt;
&lt;li&gt;IaaS&lt;/li&gt;
&lt;li&gt;PaaS&lt;/li&gt;
&lt;li&gt;Others&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;on-premises&#34;&gt;On Premises&lt;/h3&gt;
&lt;p&gt;If you already own datacenters or if you have strict privacy/security requirements for making sure the data does not leave your premises then &lt;em&gt;On Premises&lt;/em&gt; solution is the way to go.&lt;/p&gt;
&lt;p&gt;Install host operating system on the bare metal servers and then install K8s on top of it. Kubeadm is one option. However, be aware that this is a bare bones solution. You have to build/integrate authentication, authorization, dashboard, security, networking plugins, service mesh, storage, the list goes on.&lt;/p&gt;
&lt;p&gt;You could choose to install Openshift or Rancher. These come fully loaded.&lt;/p&gt;
&lt;p&gt;On Premises solutions are usually the slowest ones  to complete the installation as you have to deal  with hardware. It takes time to order, ship, install and configure them.&lt;/p&gt;
&lt;h3 id=&#34;hybrid-cloud&#34;&gt;Hybrid Cloud&lt;/h3&gt;
&lt;p&gt;Amazon Outposts, Google Anthos and Azure Stack provide rack full of servers which you can install in your datacenter. These racks are connected to their Public cloud and you manage it just like VMs on public cloud.&lt;/p&gt;
&lt;p&gt;This option gives you the flexibility of cloud deployment with the advantage of not managing the hardware.&lt;/p&gt;
&lt;p&gt;Keep in mind that this is the most costliest option. Bill can run into millions easily.&lt;/p&gt;
&lt;p&gt;Once you have Outposts, Anthos or Azure Stack rack on premises, you can use their managed K8s solution on top of it. Google Anthos GKE is one such option.&lt;/p&gt;
&lt;p&gt;The timeline depends on the cloud provider and honestly I have no idea about it.&lt;/p&gt;
&lt;h3 id=&#34;iaas&#34;&gt;IaaS&lt;/h3&gt;
&lt;p&gt;If you need full control of the K8s cluster and you are a pro in managing K8s then this is the option to go.&lt;/p&gt;
&lt;p&gt;You install K8s on top of Amazon EC2 or Google Compute Engine or Azure Virtual Machine.&lt;/p&gt;
&lt;p&gt;Several K8s deployment tools like kops, kubespray or KRIB exist. You can also install Red Hat Openshift or Rancher on the virtual machines.&lt;/p&gt;
&lt;p&gt;Use this option only when you have experience running k8s clusters.&lt;/p&gt;
&lt;h3 id=&#34;paas&#34;&gt;PaaS&lt;/h3&gt;
&lt;p&gt;If all you wanted is a K8s cluster and don&amp;rsquo;t know or don&amp;rsquo;t want to know K8s cluster management then this option is for you.&lt;/p&gt;
&lt;p&gt;Managed K8s solutions like Google GKE, Amazon EKS, Amazon Red Hat Openshift, Azure AKS does fit the bill.&lt;/p&gt;
&lt;p&gt;You click a button and you get a cluster and the kubeconfig/credentials to the cluster.&lt;/p&gt;
&lt;p&gt;You might want to customize some options, enable logging, move the API server to private endpoint etc.&lt;/p&gt;
&lt;p&gt;Usually this is a good place to start for development clusters. Deploy the k8s cluster, tune it, test it, run your applications and then customize more.&lt;/p&gt;
&lt;p&gt;Since this is a managed solution, you will not have full control of the cluster. You have to use whatever version they support, don&amp;rsquo;t get access to the API server or etcd servers barring some flags.&lt;/p&gt;
&lt;h3 id=&#34;others&#34;&gt;Others&lt;/h3&gt;
&lt;p&gt;Minikube, kind, k3s are for developments purposes. These software are light weight and are designed to run on your laptop.&lt;/p&gt;
&lt;p&gt;These solutions can be used for learning about k8s, for local testing of your applications.&lt;/p&gt;
&lt;p&gt;K8s distributions like Red Hat Openshift or Rancher can be installed on bare metal, IaaS, and  PaaS. Usually this option is useful if you have more than one type of infrastructure and you want to use the same K8s distribution everywhere. You could build automation on top of it and deploy it any where you want.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this blog post I have tried to cover different ways you can deploy your kubernetes cluster. This list is not exhaustive and I might have missed some options.&lt;/p&gt;
&lt;p&gt;Kubernetes has become the industry standard for running containers and all the major public cloud providers have K8s services.&lt;/p&gt;
&lt;p&gt;Purpose of writing this blog post is to showcase the variety of K8s deployment options you have, be it on a bare metal server, or virtual machine or managed solution like this week&amp;rsquo;s announcement of Amazon Red Hat Openshift.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback by commenting on my tweet below.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Where should I deploy my K8s cluster?&lt;br&gt;My new blog post on this topic.&lt;a href=&#34;https://t.co/sflPzY3Rnt&#34;&gt;https://t.co/sflPzY3Rnt&lt;/a&gt;&lt;br&gt;&lt;br&gt;Do read it and give me feedback.&lt;/p&gt;&amp;mdash; Vijay Kodam (@vijaykodam) &lt;a href=&#34;https://twitter.com/vijaykodam/status/1261783876596350976?ref_src=twsrc%5Etfw&#34;&gt;May 16, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


</description>
    </item>
    
    <item>
      <title>How to login securely to your Amazon EC2 Instance?</title>
      <link>https://vijay.eu/posts/how-to-login-securely-to-amazon-ec2/</link>
      <pubDate>Tue, 12 May 2020 14:42:15 +0300</pubDate>
      
      <guid>https://vijay.eu/posts/how-to-login-securely-to-amazon-ec2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/secure-ec2.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Securing the Amazon EC2 instance is the first thing you have to think while creating it. This post specifically talks about how to secure SSH/RDP port on your EC2 Instances and how not to open port 22/3389 to the Internet (0.0.0.0/0).&lt;/p&gt;
&lt;p&gt;There are several ways to secure your EC2 instances in AWS. Will discuss some of the popular ones.&lt;/p&gt;
&lt;p&gt;When EC2 instance is running in Public subnet, disable password authentication and enable SSH keys based authentication. Secure your SSH port to allow traffic from specific subnet (Ex., 3.2.132.0/24) or your own IP address (Eg., 3.2.132.23/32) by setting security group rules.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;a href=&#34;https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html&#34;&gt;*security group&lt;/a&gt;* acts as a virtual firewall for your instance to control inbound and outbound traffic.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Problem with this method is that whenever your IP address or subnet changes you have to update your security group rules. Managing SSH keys is another task, which can get quite tricky when there are more than few EC2 instances. How to store the SSH keys safely? How to grant or revoke accesses to specific users?&lt;/p&gt;
&lt;p&gt;Another way is to use bastion host, run it in Public subnet and expose it to Internet using security group rules. Create your EC2 instances in a private subnet where there is no access from Internet and no one from outside can access it. Use security group rules to allow SSH traffic into your instance only from the bastion. This way your EC2 instance traffic is secured and only from bastion host you can access your EC2 instance.&lt;/p&gt;
&lt;p&gt;However, the same problem exists as before. How will you secure your SSH/RDP port on the bastion host. You will still have to manage the SSH keys to your bastion host and open inbound ports on the instance.&lt;/p&gt;
&lt;h2 id=&#34;aws-systems-manager-session-manager&#34;&gt;AWS Systems Manager Session Manager&lt;/h2&gt;
&lt;p&gt;Session Manager is part of AWS Systems Manager service. It gives you a browser-based CLI window to access your Windows and Linux EC2 instances without opening inbound SSH/RDP port. No need to create a bastion host. No need to manage SSH keys. Access can be granted or revoked using AWS IAM.&lt;/p&gt;
&lt;p&gt;AWS Systems Manager uses SSM agent running on the EC2 instance to manage the login and other tasks.&lt;/p&gt;
&lt;p&gt;SSM Agent is preinstalled, by default, on the following Amazon Machine Images (AMIs):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Windows Server 2008-2012 R2 AMIs published in November 2016 or later&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Windows Server 2016 and 2019&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Amazon Linux&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Amazon Linux 2&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ubuntu Server 16.04&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ubuntu Server 18.04&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Amazon ECS-Optimized&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You need to create relevant IAM permissions, install or enable SSM agent on the EC2 instances. Once you do it you can either acces your instance from AWS Console or AWS CLI.&lt;/p&gt;
&lt;p&gt;For detailed instructions, refer to &lt;a href=&#34;https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-getting-started.html&#34;&gt;the documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;AWS Systems Manager Sessions Manager lets you manage your entire fleet of EC2 instances, audit the access, grant or revoke access for each instance.&lt;/p&gt;
&lt;h3 id=&#34;notes&#34;&gt;Notes&lt;/h3&gt;
&lt;p&gt;Beware of pressing CTRL-W if you are used to it on the bash shell. It will close your browser window. Change the keyboard shortcuts to update the shortcut.&lt;/p&gt;
&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
&lt;p&gt;Send your feedback or comments on my tweet below:
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;How to login securely to Amazon EC2 without opening SSH port to 0.0.0.0/0.&lt;a href=&#34;https://t.co/iAPvnoawwN&#34;&gt;https://t.co/iAPvnoawwN&lt;/a&gt;&lt;br&gt;&lt;br&gt;This tweet is used for allowing readers to comment on my blogpost. &lt;br&gt;Since it is hosted as static pages using Hugo thought this is a good way to include commenting on my blogpost.&lt;/p&gt;&amp;mdash; Vijay Kodam (@vijaykodam) &lt;a href=&#34;https://twitter.com/vijaykodam/status/1260837110812155904?ref_src=twsrc%5Etfw&#34;&gt;May 14, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ambassador API GW and Keycloak integration</title>
      <link>https://vijay.eu/posts/ambassador-keycloak-integration/</link>
      <pubDate>Sun, 23 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vijay.eu/posts/ambassador-keycloak-integration/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/cloud.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.getambassador.io/&#34;&gt;Ambassador API GW&lt;/a&gt; is an open source, Kubernetes-Native microservices API Gateway built on the Envoy Proxy.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.keycloak.org/&#34;&gt;Keycloak&lt;/a&gt; is an open source identity and access management solution. Keycloak supports OpenID Connect, SAML, OAuth2 and LDAP.&lt;/p&gt;
&lt;p&gt;Ambassador supports authenticating incoming requests. When configured, Ambassador will check with a third party authentication service prior to routing an incoming request. An AuthService manifest configures Ambassador to use an external service to check authentication and authorization for incoming requests. Each incoming request is authenticated before routing to its destination.&lt;/p&gt;
&lt;p&gt;In this blog we will be using Keycloak as our IAM solution and integrating it with Ambassador API GW. After integrating Keycloak with Ambassador, incoming API requests will be redirected to Keycloak login page for authentication before allowing access to those APIs.&lt;/p&gt;
&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Ambassador API GW is deployed and listening for API requests. Follow the &lt;a href=&#34;https://www.getambassador.io/user-guide/getting-started&#34;&gt;official instructions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;httpbin example application is configured for the URL: &lt;code&gt;http://&amp;lt;Ambassador URL&amp;gt;/httpbin&lt;/code&gt;
You can follow the instructions mentioned &lt;a href=&#34;https://www.getambassador.io/user-guide/getting-started/#3-creating-your-first-route&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Make sure &lt;code&gt;http://&amp;lt;Ambassador URL&amp;gt;/httpbin&lt;/code&gt; is routed through Ambassador API GW and it should open &lt;code&gt;httpbin.org&lt;/code&gt; website.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In some of the commands below, you need to substitute relevant IP or URL for Keycloak and Ambassador. You will find them in this notation: &lt;code&gt;&amp;lt;Ambassador IP-or-URL&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;Your-Keycloak-IP-or-URL&amp;gt;&lt;/code&gt;.       Similarly there are other variables in &lt;code&gt;&amp;lt; &amp;gt;&lt;/code&gt; which you need to substitute before running those commands.&lt;/p&gt;
&lt;h2 id=&#34;set-up-keycloak&#34;&gt;Set up Keycloak&lt;/h2&gt;
&lt;p&gt;Use your existing keycloak setup if you already have. If not you can start one quicky using below instructions.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Please note that below keycloak setup is not secure and is used only for testing the Ambassador-Keycloak integration. Do not use this in production. Use it at your own risk.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For testing purposes docker version of keycloak will be used for this demo.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker run -e KEYCLOAK_USER=&amp;lt;add-your-keycloak-user&amp;gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            -e KEYCLOAK_PASSWORD=&amp;lt;keycloak-password&amp;gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                  -p 0.0.0.0:80:8080 \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                -itd --name keycloak \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                      jboss/keycloak
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Above command will start keycloak on your Linux machine. It will set admin username, password and binds keycloak to port 80. This setup uses keycloak&amp;rsquo;s default H2 DB, which should not be used in production. Note your IP address.&lt;/p&gt;
&lt;p&gt;Login to Keycloak by visiting &lt;code&gt;http://&amp;lt;your-ip&amp;gt;&lt;/code&gt; in your browser. Use the username and password supplied in the docker run command to login to Keycloak.&lt;/p&gt;
&lt;p&gt;Use the existing &amp;ldquo;master&amp;rdquo; realm. Create a client and a user for our testing purposes.
Click on &lt;code&gt;Clients -&amp;gt; Create&lt;/code&gt;. Create button is on the right side of the page.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture6.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Add &lt;code&gt;Client ID&lt;/code&gt; as &lt;code&gt;test&lt;/code&gt;. Select &amp;ldquo;&lt;code&gt;Client Protocol&lt;/code&gt;&amp;rdquo; as &amp;ldquo;openid-connect&amp;rdquo;. You can leave other fields empty. Click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture1.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;After saving, a new window will open with more details. Turn On &lt;code&gt;Authorization Enabled&lt;/code&gt; option. It will automatically turn On &lt;code&gt;Service Accounts Enabled&lt;/code&gt; option. Leave it like that.&lt;/p&gt;
&lt;p&gt;Fill &lt;code&gt;Valid Redirect URIs&lt;/code&gt; with &lt;code&gt;http://&amp;lt;Ambassador URL&amp;gt;/*&lt;/code&gt;. Click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture2.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture8.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;On the same page, go to &lt;code&gt;Credentials&lt;/code&gt; tab as shown below. Note the secret which is needed when creating &amp;ldquo;ambassador-auth-client-secret&amp;rdquo; in the next section. Use it wherever &lt;code&gt;&amp;lt;YOUR_OIDC_CLIENT_SECRET&amp;gt;&lt;/code&gt; is mentioned.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture4.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Click Users section on the keycloak page, to create users. Add username, email and select email verified. Click Save.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture9.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the same page, go to Credentials tab.  Set the new password, and turn Temporary to Off.&lt;br&gt;
Click Reset Password.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture10.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;When dialog window opens click Change Password.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture11.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Please note that this is done only for testing ambassador-keycloak integration. 
Please do not do this in production or in any setup. Follow these instructions at your own risk.&lt;/p&gt;
&lt;p&gt;Now go back and click Users section in Keycloak. In the Users page, click &amp;ldquo;View all Users&amp;rdquo; and you should see the newly created user.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vijay.eu/images/Capture12.JPG&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;setup-oidc-auth-integration-with-keycloak&#34;&gt;Setup OIDC Auth integration with Keycloak&lt;/h2&gt;
&lt;p&gt;Thanks to Antti Myyra for developing Ambassador-Auth-OIDC, which will be used to integrate Keycloak with Ambassador API GW.&lt;/p&gt;
&lt;p&gt;Run below commands to clone ambassador-auth-oidc. Below you can choose to run it either in docker or in k8s. Don&amp;rsquo;t run both.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/ajmyyra/ambassador-auth-oidc.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd ambassador-auth-oidc/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;running-ambassador-auth-in-docker&#34;&gt;Running ambassador auth In Docker&lt;/h3&gt;
&lt;p&gt;Use these instructions if your Ambassador API gateway is running as docker container and not in k8s.&lt;/p&gt;
&lt;p&gt;Above setup is running keycloak as docker container and listening on port 80. Below ambassador-auth-oidc docker container will listen on port 8080.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker run -p 0.0.0.0:8080:8080 \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      -e OIDC_PROVIDER=&amp;#34;http://&amp;lt;Your-Keycloak-IP-or-URL&amp;gt;/auth/realms/master&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      -e SELF_URL=&amp;#34;http://&amp;lt;Ambassador IP-or-URL&amp;gt;:8080&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      -e OIDC_SCOPES=&amp;#34;profile email&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      -e CLIENT_ID=&amp;#34;test&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      -e CLIENT_SECRET=&amp;#34;&amp;lt;YOUR_OIDC_CLIENT_SECRET&amp;gt;&amp;#34; \
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      ajmyyra/ambassador-auth-oidc:1.3
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;running-ambassador-auth-in-kubernetes&#34;&gt;Running Ambassador Auth in Kubernetes&lt;/h3&gt;
&lt;p&gt;Use this setup if you are already running Ambassador API GW in K8s.
Make sure Ambassador API GW is up and running before creating secrets.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create secret generic ambassador-auth-jwt-key --from-literal=jwt-key=$(openssl rand -base64 64|tr -d &amp;#39;\n &amp;#39;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create secret generic ambassador-auth-redis-password --from-literal=redis-password=$(openssl rand -base64 20)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create secret generic ambassador-auth-oidc-provider --from-literal=oidc-provider=&amp;#34;http://&amp;lt;Your-Keycloak-IP-or-URL&amp;gt;/auth/realms/master&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create secret generic ambassador-auth-self-url --from-literal=self-url=&amp;#34;http://&amp;lt;Ambassador IP-or-URL&amp;gt;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create secret generic ambassador-auth-client-id --from-literal=client-id=&amp;#34;test&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create secret generic ambassador-auth-client-secret --from-literal=client-secret=&amp;lt;YOUR_OIDC_CLIENT_SECRET&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl get secrets # To confirm they&amp;#39;ve been created
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Run below commands in the root directory of ambassador-auth-oidc. This will start the ambassador-auth-oidc container on K8s.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd ambassador-auth-oidc/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cp misc/auth-deployment.yaml.example auth-deployment.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cp misc/auth-service.yaml.example auth-service.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create -f auth-deployment.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl create -f auth-service.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Make sure ambassador-auth-oidc is up and running. Also check the logs to make sure everything is alright.&lt;/p&gt;
&lt;p&gt;Now go to &lt;code&gt;http://&amp;lt;Ambassador IP-or-URL&amp;gt;/httpbin&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It should automatically redirect you to Keycloak page for logging in.
Enter your &amp;ldquo;test&amp;rdquo; user credentials. After successful login it should automatically redirect you to &lt;code&gt;http://&amp;lt;Ambassador IP-or-URL&amp;gt;/httpbin&lt;/code&gt; page.&lt;/p&gt;
&lt;p&gt;We have successfully integrated Keycloak with Ambassador API GW and tested API Authentication.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
